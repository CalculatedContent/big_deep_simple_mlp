{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-20T21:52:04.548207",
     "start_time": "2016-04-20T21:52:04.544771"
    }
   },
   "source": [
    "## 2 Layer MLP for Dark Knoweldge Experiments w/AlignMNIST\n",
    "\n",
    "75 epochs of RMSProp on AlignMNIST\n",
    "\n",
    "800 x 800 network with normalized the weights after each epoch\n",
    "\n",
    "no dropout .. another baseline\n",
    "\n",
    "\n",
    "see  http://www.r2rt.com/posts/implementations/2016-03-29-implementing-batch-normalization-tensorflow/\n",
    "\n",
    "https://github.com/tensorflow/tensorflow/blob/b3621c95160a916d4d255f9f44318b9d465701af/tensorflow/contrib/layers/python/layers/layers.py\n",
    "\n",
    "\n",
    "https://www.reddit.com/r/MachineLearning/comments/2bopxs/question_about_the_maxnorm_constraint_used_with/\n",
    "\n",
    "\n",
    "\n",
    "https://arxiv.org/pdf/1207.0580.pdf\n",
    "\n",
    "https://arxiv.org/pdf/1503.02531v1.pdf\n",
    "\n",
    "http://www.kdnuggets.com/2015/04/preventing-overfitting-neural-networks.html\n",
    "\n",
    "https://www.reddit.com/r/MachineLearning/comments/2bopxs/question_about_the_maxnorm_constraint_used_with/\n",
    "\n",
    "and https://github.com/tensorflow/tensorflow/issues/608"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-16T22:37:57.602940",
     "start_time": "2016-06-16T22:37:55.723796"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-16T22:37:57.628912",
     "start_time": "2016-06-16T22:37:57.608540"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run augmentmnist.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-16T22:37:57.635100",
     "start_time": "2016-06-16T22:37:57.631672"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 75\n",
    "batch_size = 125\n",
    "\n",
    "learning_rate = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-16T22:37:57.643958",
     "start_time": "2016-06-16T22:37:57.637188"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Network Parameters\n",
    "n_hidden_1 = 800 # 1st layer num features\n",
    "n_hidden_2 = 800 # 2nd layer num features\n",
    "n_input = 784 # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "\n",
    "std_0  = np.sqrt(6.0/(n_input+n_hidden_1))\n",
    "std_h1 = np.sqrt(6.0/(n_hidden_1+n_hidden_2))\n",
    "std_h2 = np.sqrt(6.0/(n_hidden_2+n_classes))\n",
    "\n",
    "logfile = \"2BwD-layer-dlk-alignmnist-4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-16T22:37:57.652907",
     "start_time": "2016-06-16T22:37:57.645573"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "xt = tf.placeholder(\"float\", [None, n_input])\n",
    "yt = tf.placeholder(\"float\", [None, n_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### need to try again with Dropout on both layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-16T22:37:58.526181",
     "start_time": "2016-06-16T22:37:58.522441"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def multilayer_perceptron(_X, _weights, _biases):\n",
    "    layer_1 = tf.nn.relu(tf.add(tf.matmul(_X, _weights['h1']), _biases['b1']))\n",
    "    layer_2 =tf.nn.relu(tf.add(tf.matmul(layer_1, _weights['h2']), _biases['b2']))\n",
    "    return tf.matmul(layer_2, weights['out']) + biases['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-16T22:37:58.680867",
     "start_time": "2016-06-16T22:37:58.676985"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def multilayer_perceptron_test(_X, _weights, _biases):\n",
    "    layer_1 = tf.nn.relu(tf.add(tf.matmul(_X, _weights['h1']), _biases['b1']))\n",
    "    layer_2 = tf.nn.relu(tf.add(tf.matmul(layer_1, _weights['h2']), _biases['b2']))\n",
    "    return tf.matmul(layer_2, weights['out']) + biases['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-16T22:37:58.880030",
     "start_time": "2016-06-16T22:37:58.843497"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1], stddev=std_0)),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2], stddev=std_h1)),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes], stddev=std_h2))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1], stddev=0.1)),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2], stddev=0.01)),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes], stddev=0.001))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-16T22:37:59.536509",
     "start_time": "2016-06-16T22:37:59.525239"
    },
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mlp = multilayer_perceptron(x, weights, biases )\n",
    "mlp_test = multilayer_perceptron_test(xt, weights, biases  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-16T22:38:00.029439",
     "start_time": "2016-06-16T22:38:00.018054"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cost =  tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(mlp, y)) \n",
    "gs = tf.get_variable(\"global_step\",[],trainable=False,initializer=tf.constant_initializer(0))\n",
    "lr = tf.constant(learning_rate) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-16T15:33:44.245778",
     "start_time": "2016-06-16T15:33:44.109400"
    },
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "train_op = tf.contrib.layers.optimize_loss(cost, global_step=gs, learning_rate=lr,optimizer=\"RMSProp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-15T23:46:29.570951",
     "start_time": "2016-06-15T23:46:29.568744"
    }
   },
   "source": [
    "### don't include dropout in accuracy calculations"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-16T15:33:45.106743",
     "start_time": "2016-06-16T15:33:45.085919"
    },
    "collapsed": false
   },
   "source": [
    "#with tf.name_scope(\"training accuracy\"):\n",
    "pred = tf.equal(tf.argmax(mlp, 1), tf.argmax(y, 1)) # Count correct predictions\n",
    "train_acc_op = tf.reduce_mean(tf.cast(pred, \"float\"))  # Cast boolean to float to average\n",
    "tf.scalar_summary(\"training accuracy\", train_acc_op)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-16T15:33:46.093438",
     "start_time": "2016-06-16T15:33:46.081762"
    },
    "collapsed": false
   },
   "source": [
    "test_pred = tf.equal(tf.argmax(mlp_test, 1), tf.argmax(yt, 1)) # Count correct predictions\n",
    "test_acc_op = tf.reduce_mean(tf.cast(test_pred, \"float\"))  # Cast boolean to float to average\n",
    "tf.scalar_summary(\"test 0 accuracy\", test_acc_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-16T22:38:15.361463",
     "start_time": "2016-06-16T22:38:15.129739"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36m2-layer-dk-alignmnist\u001b[m\u001b[m           \u001b[1m\u001b[36m2-layer-modern-mlp-alignmnist\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[36m2-layer-dlk-alignmnist\u001b[m\u001b[m          \u001b[1m\u001b[36m2BwD-layer-dlk-alignmnist\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[36m2-layer-mlp-alignmnist-wdropout\u001b[m\u001b[m \u001b[1m\u001b[36m5-layer-mlp-alignmnist-wdropout\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[36m2-layer-mlp-mnist-temp\u001b[m\u001b[m          \u001b[1m\u001b[36m5-layer-mlp-infimnist\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[36m2-layer-mlp-mnist-watch\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!rm -rf ./logs/{logfile}\n",
    "!ls logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-04T21:57:37.534602",
     "start_time": "2016-05-04T21:57:37.532739"
    },
    "collapsed": true
   },
   "source": [
    "### Original MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-16T22:38:16.932266",
     "start_time": "2016-06-16T22:38:16.092793"
    },
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./train-images-idx3-ubyte.gz\n",
      "Extracting ./train-labels-idx1-ubyte.gz\n",
      "Extracting ./t10k-images-idx3-ubyte.gz\n",
      "Extracting ./t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\".\", one_hot=True)\n",
    "trX_0, trY_0 = mnist.train.images, mnist.train.labels\n",
    "teX_0, teY_0 = mnist.test.images, mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-16T22:38:17.617307",
     "start_time": "2016-06-16T22:38:17.612219"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alignmnist = AlignMNIST()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-14T18:12:43.510102",
     "start_time": "2016-06-14T18:12:43.502711"
    }
   },
   "source": [
    " see https://github.com/tensorflow/tensorflow/issues/424"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-16T22:38:18.678973",
     "start_time": "2016-06-16T22:38:18.674926"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "\n",
    "from tensorflow.python.ops import variable_scope as vs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-16T22:38:19.711451",
     "start_time": "2016-06-16T22:38:19.673352"
    },
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# do i have this right  ?\n",
    "\n",
    "def max_norm_constraint(_weights, _biases):\n",
    "    \n",
    "    norms0 = np.array([50.0, 60.0, 6.0, 3.0, 1.0, 1.0])\n",
    "    norms0 = norms0*1.0\n",
    "\n",
    "    n0 = tf.constant(norms0[0], dtype=tf.float32)\n",
    "    n1 = tf.constant(norms0[1],  dtype=tf.float32)\n",
    "    n2 = tf.constant(norms0[2],  dtype=tf.float32)\n",
    "    n3 = tf.constant(norms0[3],  dtype=tf.float32)\n",
    "    n4 = tf.constant(norms0[4],  dtype=tf.float32)\n",
    "    n5 = tf.constant(norms0[5],  dtype=tf.float32)\n",
    "    \n",
    "    norm_h1 =   tf.sqrt(tf.reduce_sum(tf.square(_weights['h1'])))\n",
    "    norm_h2 =   tf.sqrt(tf.reduce_sum(tf.square(_weights['h2'])))\n",
    "    norm_hout = tf.sqrt(tf.reduce_sum(tf.square(_weights['out'])))\n",
    "                        \n",
    "    norm_b1 =   tf.sqrt(tf.reduce_sum(tf.square(_biases['b1'])))\n",
    "    norm_b2 =   tf.sqrt(tf.reduce_sum(tf.square(_biases['b2'])))\n",
    "    norm_bout = tf.sqrt(tf.reduce_sum(tf.square(_biases['out'])))\n",
    "\n",
    "    \n",
    "    pred = tf.greater(norm_h1 , n0)\n",
    "    _weights['h1'] = control_flow_ops.cond(pred, lambda: tf.div(_weights['h1'], norm_h1), lambda: _weights['h1'])\n",
    "    \n",
    "    pred = tf.greater(norm_h2 , n1)\n",
    "    _weights['h2'] = control_flow_ops.cond(pred, lambda: tf.div(_weights['h2'], norm_h2), lambda: _weights['h2'])\n",
    "    \n",
    "    pred = tf.greater(norm_hout , n2)\n",
    "    _weights['out'] = control_flow_ops.cond(pred, lambda: tf.div(_weights['out'], norm_hout), lambda: _weights['out'])\n",
    "            \n",
    "    pred = tf.greater(norm_b1 , n3)\n",
    "    _biases['b1'] = control_flow_ops.cond(pred, lambda: tf.div(_biases['b1'], norm_b1), lambda: _biases['b1'])\n",
    "    \n",
    "    pred = tf.greater(norm_b2 , n4)\n",
    "    _biases['b2'] = control_flow_ops.cond(pred, lambda: tf.div(_biases['b2'], norm_b2), lambda: _biases['b2'])\n",
    "\n",
    "    pred = tf.greater(norm_bout , n5)\n",
    "    _biases['out'] = control_flow_ops.cond(pred, lambda: tf.div(_biases['out'], norm_bout), lambda: _biases['out'])\n",
    "       \n",
    "    return tf.constant(norms0[0], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-16T15:33:51.063945",
     "start_time": "2016-06-16T15:33:51.003699"
    },
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-17T08:40:16.507359",
     "start_time": "2016-06-17T06:32:35.619442"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0.96998334, 0.95929998)\n",
      "[1.000017, 50.92754, 0.9999997, 2.8767266, 0.38060847, 0.019276755]\n",
      "(1, 0.95885003, 0.97460002)\n",
      "[1.0000167, 53.540356, 1.0000001, 2.8934255, 0.61607522, 0.066759184]\n",
      "(0, 0.97486669, 0.96749997)\n",
      "[49.990677, 50.907757, 1.0, 2.756165, 0.37869224, 0.022361267]\n",
      "(1, 0.96385002, 0.9777)\n",
      "[1.0000156, 53.527569, 1.0000001, 2.7622385, 0.62265515, 0.057664622]\n",
      "(0, 0.97235, 0.96579999)\n",
      "[50.000713, 50.935467, 0.99999982, 2.7350247, 0.36257568, 0.017452713]\n",
      "(1, 0.9684, 0.97729999)\n",
      "[1.0000184, 53.530972, 0.99999982, 2.7530963, 0.55639946, 0.051071223]\n",
      "(0, 0.96885002, 0.95920002)\n",
      "[49.995628, 50.953915, 0.99999994, 2.9125488, 0.37396094, 0.024777452]\n",
      "(1, 0.96641666, 0.97780001)\n",
      "[1.0000163, 53.568703, 1.0, 2.9249277, 0.61312139, 0.058107249]\n",
      "(0, 0.97451669, 0.96670002)\n",
      "[1.0000157, 50.924599, 0.99999976, 2.8730028, 0.3683621, 0.027475618]\n",
      "(1, 0.96945, 0.98269999)\n",
      "[1.0000178, 53.530125, 1.0000001, 2.8856587, 0.60122418, 0.064867288]\n",
      "(0, 0.97065002, 0.96420002)\n",
      "[1.0000157, 50.822449, 0.9999997, 2.7012658, 0.35330543, 0.020614164]\n",
      "(1, 0.95921665, 0.9745)\n",
      "[1.0000151, 53.420876, 1.0000001, 2.7137015, 0.56904775, 0.053243078]\n",
      "(0, 0.96773332, 0.95990002)\n",
      "[1.0000153, 50.826626, 1.0, 2.7940764, 0.36335537, 0.027420137]\n",
      "(1, 0.96364999, 0.97399998)\n",
      "[1.0000179, 53.42614, 1.0000002, 2.803489, 0.58510596, 0.054764029]\n",
      "(0, 0.9752, 0.97000003)\n",
      "[1.0000162, 50.890965, 0.99999976, 2.8695803, 0.3540231, 0.02699006]\n",
      "(1, 0.96885002, 0.97970003)\n",
      "[1.0000157, 53.51622, 1.0000002, 2.8780589, 0.58065963, 0.062361676]\n",
      "(0, 0.96591669, 0.96039999)\n",
      "[1.0000193, 50.918381, 1.0000001, 2.778276, 0.35312372, 0.022264818]\n",
      "(1, 0.96385002, 0.97640002)\n",
      "[1.0000145, 53.48494, 0.99999946, 2.7888839, 0.56666797, 0.055342883]\n",
      "(0, 0.97443336, 0.96740001)\n",
      "[49.980507, 50.862331, 1.0, 2.7979827, 0.35732207, 0.023671536]\n",
      "(1, 0.96476668, 0.97430003)\n",
      "[1.0000168, 53.454739, 1.0, 2.8002858, 0.58212137, 0.049010027]\n",
      "(0, 0.97191668, 0.96380001)\n",
      "[49.929234, 50.880993, 0.99999988, 2.8428619, 0.35699555, 0.026017824]\n",
      "(1, 0.96653336, 0.97619998)\n",
      "[1.0000167, 53.470264, 0.99999976, 2.8537741, 0.58003551, 0.055631515]\n",
      "(0, 0.97406667, 0.96759999)\n",
      "[1.0000166, 50.940628, 1.0000001, 2.837714, 0.36658946, 0.029240193]\n",
      "(1, 0.96539998, 0.97970003)\n",
      "[1.0000169, 53.524902, 1.0, 2.8426883, 0.61969852, 0.065458141]\n",
      "(0, 0.9544, 0.94870001)\n",
      "[1.0000148, 50.87191, 1.0, 2.8817334, 0.3841919, 0.033071924]\n",
      "(1, 0.9497, 0.96609998)\n",
      "[1.0000148, 53.498466, 1.0, 2.8977497, 0.59992927, 0.057555925]\n",
      "(0, 0.96563333, 0.95700002)\n",
      "[1.0000153, 50.861198, 1.0000001, 2.8487859, 0.36239704, 0.032241065]\n",
      "(1, 0.96210003, 0.97310001)\n",
      "[1.000016, 53.50423, 0.99999988, 2.8605552, 0.59835184, 0.065564066]\n",
      "(0, 0.97418332, 0.96780002)\n",
      "[1.0000198, 50.93124, 1.0000001, 2.8304467, 0.35196421, 0.02605392]\n",
      "(1, 0.96025002, 0.97460002)\n",
      "[1.0000172, 53.567638, 0.99999982, 2.8371611, 0.57707393, 0.059184026]\n",
      "(0, 0.97235, 0.9648)\n",
      "[1.0000142, 50.952728, 1.0000001, 2.8853395, 0.34566087, 0.025663774]\n",
      "(1, 0.95411664, 0.96850002)\n",
      "[1.0000173, 53.591976, 1.0000004, 2.8935962, 0.5675894, 0.048138615]\n",
      "(0, 0.96918333, 0.9623)\n",
      "[1.0000162, 50.881264, 1.0000001, 2.7930098, 0.37094587, 0.016652042]\n",
      "(1, 0.96103334, 0.97149998)\n",
      "[1.0000137, 53.490391, 1.0, 2.8063152, 0.60702485, 0.057617817]\n",
      "(0, 0.9745, 0.96789998)\n",
      "[1.0000149, 50.91605, 1.0, 2.7885134, 0.36343342, 0.023819007]\n",
      "(1, 0.96531665, 0.97829998)\n",
      "[1.0000141, 53.522068, 1.0000002, 2.789418, 0.60630041, 0.051591542]\n",
      "(0, 0.96810001, 0.96249998)\n",
      "[49.977612, 50.934597, 1.0000001, 2.8805339, 0.35472098, 0.018664306]\n",
      "(1, 0.96566665, 0.97600001)\n",
      "[1.0000216, 53.560612, 0.99999982, 2.8906672, 0.55360711, 0.053096704]\n",
      "(0, 0.97098333, 0.96579999)\n",
      "[1.0000155, 50.932449, 1.0, 2.6607754, 0.36634141, 0.022368256]\n",
      "(1, 0.96673334, 0.98079997)\n",
      "[1.0000167, 53.538357, 1.0000002, 2.6815419, 0.58903372, 0.056001782]\n",
      "(0, 0.97491664, 0.9673)\n",
      "[49.985912, 50.901463, 1.0000001, 2.8831728, 0.37138125, 0.022448597]\n",
      "(1, 0.96695, 0.97689998)\n",
      "[1.0000165, 53.500172, 1.0000002, 2.8981783, 0.6084767, 0.059165452]\n",
      "(0, 0.97496665, 0.96679997)\n",
      "[1.0000175, 50.911713, 1.0000001, 2.696403, 0.36073729, 0.021696063]\n",
      "(1, 0.95829999, 0.9763)\n",
      "[1.000016, 53.511841, 0.99999982, 2.7049317, 0.57463193, 0.053143103]\n",
      "(0, 0.96903336, 0.96429998)\n",
      "[50.000717, 50.962067, 0.99999994, 2.8298428, 0.37987405, 0.027217451]\n",
      "(1, 0.96136665, 0.97350001)\n",
      "[1.0000172, 53.565346, 1.0000002, 2.826628, 0.58220357, 0.0459578]\n",
      "(0, 0.97521669, 0.96829998)\n",
      "[1.000015, 50.889957, 0.9999997, 2.7468908, 0.36910588, 0.022478014]\n",
      "(1, 0.9641, 0.97850001)\n",
      "[1.000017, 53.442341, 0.99999988, 2.7517607, 0.57570773, 0.046970081]\n",
      "(0, 0.97183335, 0.96609998)\n",
      "[1.000016, 50.879093, 1.0000001, 2.8434317, 0.35995436, 0.027257562]\n",
      "(1, 0.95708334, 0.97399998)\n",
      "[1.0000128, 53.525089, 1.0000001, 2.8466785, 0.57279336, 0.061108958]\n",
      "(0, 0.96773332, 0.96079999)\n",
      "[1.0000176, 50.883778, 0.99999964, 2.8179605, 0.36485848, 0.021355283]\n",
      "(1, 0.96481669, 0.97890002)\n",
      "[1.0000176, 53.494869, 1.0000001, 2.8311577, 0.60233796, 0.054606881]\n",
      "(0, 0.97081667, 0.96469998)\n",
      "[49.906662, 50.892262, 0.99999994, 2.8900545, 0.36061263, 0.029162658]\n",
      "(1, 0.96476668, 0.97610003)\n",
      "[1.000015, 53.523991, 1.0000001, 2.9018588, 0.60438496, 0.063065626]\n",
      "(0, 0.97558331, 0.96700001)\n",
      "[49.927505, 50.899693, 1.0, 2.8644547, 0.359759, 0.029575339]\n",
      "(1, 0.96451664, 0.97589999)\n",
      "[1.000017, 53.473709, 0.9999997, 2.8914728, 0.59150791, 0.059912868]\n",
      "(0, 0.97140002, 0.9641)\n",
      "[49.984074, 50.841862, 0.99999976, 2.7242973, 0.35774747, 0.0076253214]\n",
      "(1, 0.96925002, 0.97970003)\n",
      "[1.0000154, 53.424614, 1.0, 2.7476628, 0.57087117, 0.050241761]\n",
      "(0, 0.97095001, 0.9666)\n",
      "[1.0000132, 50.915916, 0.99999994, 2.7971356, 0.36399084, 0.022653092]\n",
      "(1, 0.96748334, 0.97729999)\n",
      "[1.0000161, 53.516445, 0.99999988, 2.8162808, 0.58980477, 0.055751204]\n",
      "(0, 0.95674998, 0.94859999)\n",
      "[49.985992, 50.92585, 0.99999982, 2.8105903, 0.37502277, 0.026711127]\n",
      "(1, 0.9612667, 0.97549999)\n",
      "[1.0000149, 53.536121, 0.99999994, 2.8191445, 0.577793, 0.050797157]\n",
      "(0, 0.96735001, 0.95920002)\n",
      "[49.992851, 50.862564, 1.0000001, 2.7397482, 0.34986478, 0.026597612]\n",
      "(1, 0.95738333, 0.97039998)\n",
      "[1.0000147, 53.490227, 1.0, 2.7560818, 0.56476682, 0.062980898]\n",
      "(0, 0.95291668, 0.94340003)\n",
      "[1.0000155, 50.877838, 1.0000001, 2.7630894, 0.37253338, 0.022718973]\n",
      "(1, 0.95091665, 0.96850002)\n",
      "[1.0000165, 53.489517, 0.99999982, 2.7894466, 0.58475953, 0.048442643]\n",
      "(0, 0.97718334, 0.97229999)\n",
      "[49.974445, 50.869312, 1.0000002, 2.7525833, 0.37191471, 0.021477688]\n",
      "(1, 0.96128333, 0.9756)\n",
      "[1.0000142, 53.461384, 1.0000001, 2.7744544, 0.61099648, 0.052689403]\n",
      "(0, 0.97598332, 0.96799999)\n",
      "[1.0000167, 50.920368, 0.99999976, 2.9184501, 0.37166908, 0.023583716]\n",
      "(1, 0.96153331, 0.97430003)\n",
      "[1.0000181, 53.529381, 0.99999976, 2.9235458, 0.61074197, 0.058614213]\n",
      "(0, 0.97381669, 0.96719998)\n",
      "[1.0000149, 50.977772, 0.99999982, 2.8272948, 0.36355981, 0.026267249]\n",
      "(1, 0.95486665, 0.97280002)\n",
      "[1.0000143, 53.526264, 0.99999994, 2.8180759, 0.60059142, 0.059196189]\n",
      "(0, 0.96876669, 0.96090001)\n",
      "[1.000017, 50.938091, 1.0, 2.8796911, 0.37050515, 0.031917367]\n",
      "(1, 0.96569997, 0.97729999)\n",
      "[1.0000162, 53.503494, 1.0, 2.8864105, 0.58848524, 0.065806188]\n",
      "(0, 0.96708333, 0.96270001)\n",
      "[49.955547, 50.835979, 0.99999988, 2.9078405, 0.3611663, 0.017487355]\n",
      "(1, 0.96681666, 0.97719997)\n",
      "[1.0000175, 53.409416, 0.99999994, 2.9146433, 0.61665529, 0.051537361]\n",
      "(0, 0.97318333, 0.96810001)\n",
      "[1.0000175, 50.870468, 0.99999994, 2.7386017, 0.36191359, 0.023741189]\n",
      "(1, 0.96853334, 0.97909999)\n",
      "[1.0000168, 53.467007, 1.0000001, 2.7594972, 0.57029706, 0.058577072]\n",
      "(0, 0.97783333, 0.97180003)\n",
      "[1.0000159, 50.917858, 1.0000001, 2.9282799, 0.36095461, 0.020651452]\n",
      "(1, 0.96601665, 0.97649997)\n",
      "[1.0000186, 53.536434, 1.0000001, 2.9269891, 0.59945667, 0.056724001]\n",
      "(0, 0.97251666, 0.96329999)\n",
      "[1.0000162, 50.877087, 1.0000001, 2.7225003, 0.38237503, 0.031053251]\n",
      "(1, 0.95730001, 0.97369999)\n",
      "[1.0000182, 53.47863, 1.0000002, 2.7281346, 0.60203934, 0.070472933]\n",
      "(0, 0.97323334, 0.96640003)\n",
      "[1.0000173, 50.934605, 0.99999994, 2.7881818, 0.37040237, 0.028279265]\n",
      "(1, 0.96890002, 0.97799999)\n",
      "[1.0000172, 53.589817, 1.0000004, 2.7915542, 0.58258343, 0.063178517]\n",
      "(0, 0.97404999, 0.9677)\n",
      "[49.953739, 50.960316, 1.0000001, 2.787766, 0.38867322, 0.030657448]\n",
      "(1, 0.96318334, 0.97670001)\n",
      "[1.0000131, 53.57893, 0.99999994, 2.7971542, 0.62398666, 0.061247937]\n",
      "(0, 0.97513336, 0.96850002)\n",
      "[1.0000161, 50.89011, 1.0, 2.8418999, 0.37231997, 0.021632401]\n",
      "(1, 0.96039999, 0.97579998)\n",
      "[1.0000156, 53.489719, 1.0, 2.866663, 0.60695904, 0.066096053]\n",
      "(0, 0.96271664, 0.95670003)\n",
      "[49.923473, 50.904026, 1.0000001, 2.8243499, 0.36785084, 0.021125719]\n",
      "(1, 0.96160001, 0.97250003)\n",
      "[1.0000161, 53.533859, 1.0000001, 2.8232355, 0.57265991, 0.057187218]\n",
      "(0, 0.96413332, 0.95289999)\n",
      "[1.0000185, 50.821026, 1.0000002, 2.7788675, 0.36849761, 0.029428545]\n",
      "(1, 0.96921664, 0.9777)\n",
      "[1.0000176, 53.412075, 1.0, 2.8003159, 0.58152008, 0.058929592]\n",
      "(0, 0.97231668, 0.96649998)\n",
      "[1.0000151, 50.889832, 0.99999988, 2.9510243, 0.36465535, 0.017621417]\n",
      "(1, 0.95735002, 0.97049999)\n",
      "[1.0000135, 53.498425, 0.99999994, 2.9649789, 0.59981912, 0.067257598]\n",
      "(0, 0.9740833, 0.96719998)\n",
      "[1.0000167, 50.785908, 1.0000002, 2.9305594, 0.36295956, 0.021150036]\n",
      "(1, 0.95676666, 0.97219998)\n",
      "[1.0000155, 53.367298, 1.0000001, 2.9451911, 0.5893718, 0.056507189]\n",
      "(0, 0.97610003, 0.96820003)\n",
      "[49.97353, 50.863682, 1.0000001, 2.7723937, 0.36108696, 0.023100434]\n",
      "(1, 0.96328336, 0.97509998)\n",
      "[1.0000155, 53.448528, 1.0000002, 2.7824221, 0.59408885, 0.056548048]\n",
      "(0, 0.96813333, 0.96030003)\n",
      "[49.967266, 50.874104, 0.99999976, 2.9095025, 0.3614794, 0.035430372]\n",
      "(1, 0.9683333, 0.98110002)\n",
      "[1.000015, 53.49934, 0.99999988, 2.9186344, 0.59742528, 0.072346315]\n",
      "(0, 0.97219998, 0.96560001)\n",
      "[1.0000162, 50.878876, 1.0, 2.816819, 0.35387453, 0.025757741]\n",
      "(1, 0.96354997, 0.97589999)\n",
      "[1.0000178, 53.490704, 0.99999964, 2.835778, 0.56728077, 0.060836762]\n",
      "(0, 0.96638334, 0.96020001)\n",
      "[1.0000169, 50.891029, 0.99999976, 2.6713991, 0.35211638, 0.026298309]\n",
      "(1, 0.96224999, 0.97549999)\n",
      "[1.0000176, 53.501492, 1.0, 2.6756582, 0.60063004, 0.060748391]\n",
      "(0, 0.97318333, 0.96759999)\n",
      "[49.977493, 50.920033, 0.99999994, 2.7713215, 0.3617073, 0.024535788]\n",
      "(1, 0.96539998, 0.97750002)\n",
      "[1.0000157, 53.538815, 1.0, 2.7713721, 0.58937758, 0.055804461]\n",
      "(0, 0.97681665, 0.96899998)\n",
      "[49.954311, 50.797672, 0.9999997, 2.8138187, 0.37872964, 0.02992647]\n",
      "(1, 0.96139997, 0.97649997)\n",
      "[1.0000149, 53.397293, 1.0000001, 2.8138897, 0.59850585, 0.061652254]\n",
      "(0, 0.96920002, 0.95950001)\n",
      "[1.0000139, 50.902027, 1.0000001, 2.8610458, 0.3576076, 0.014505114]\n",
      "(1, 0.96286666, 0.97530001)\n",
      "[1.000016, 53.505531, 0.99999994, 2.8787758, 0.57704365, 0.048160248]\n",
      "(0, 0.97716665, 0.96990001)\n",
      "[1.0000157, 50.920975, 0.99999976, 2.8641453, 0.35728678, 0.020333992]\n",
      "(1, 0.96845001, 0.97780001)\n",
      "[1.000018, 53.531898, 1.0, 2.8567059, 0.58086324, 0.051893715]\n",
      "(0, 0.96824998, 0.96020001)\n",
      "[1.0000148, 50.907814, 0.99999994, 2.8126602, 0.35511994, 0.021666067]\n",
      "(1, 0.96601665, 0.97820002)\n",
      "[1.0000188, 53.545818, 1.0000004, 2.8079805, 0.57984459, 0.057331394]\n",
      "(0, 0.97764999, 0.97119999)\n",
      "[49.983143, 50.92086, 1.0, 2.8133657, 0.36928329, 0.022930495]\n",
      "(1, 0.95963335, 0.97479999)\n",
      "[1.0000178, 53.562847, 0.99999994, 2.8172889, 0.60601461, 0.050179932]\n",
      "(0, 0.97413331, 0.96969998)\n",
      "[1.000016, 50.900726, 0.99999988, 2.8490202, 0.38402352, 0.024221949]\n",
      "(1, 0.95411664, 0.9727)\n",
      "[1.0000181, 53.477547, 1.0000001, 2.8704114, 0.63270819, 0.062007204]\n",
      "(0, 0.96095002, 0.94989997)\n",
      "[1.0000181, 50.949444, 0.99999982, 2.872268, 0.37548143, 0.027257603]\n",
      "(1, 0.96228331, 0.97850001)\n",
      "[1.0000156, 53.594433, 1.0000002, 2.8853838, 0.6095472, 0.06075608]\n",
      "(0, 0.97444999, 0.96630001)\n",
      "[1.000016, 50.925919, 0.99999994, 2.8095558, 0.36373505, 0.02117037]\n",
      "(1, 0.96871668, 0.98180002)\n",
      "[1.0000172, 53.553398, 1.0000001, 2.8152673, 0.60877967, 0.054705754]\n",
      "(0, 0.97253335, 0.96710002)\n",
      "[50.000401, 50.896919, 1.0000001, 2.7582185, 0.35520092, 0.024661336]\n",
      "(1, 0.96031666, 0.97329998)\n",
      "[1.000015, 53.467052, 1.0, 2.7502003, 0.56460899, 0.054221965]\n",
      "(0, 0.97686666, 0.96789998)\n",
      "[1.0000199, 50.956444, 1.0000001, 2.9214847, 0.36923987, 0.028299756]\n",
      "(1, 0.96574998, 0.97829998)\n",
      "[1.0000162, 53.556625, 0.99999976, 2.9351003, 0.61112046, 0.06513875]\n",
      "(0, 0.95773333, 0.95190001)\n",
      "[49.982063, 50.951935, 1.0, 2.8766119, 0.37477368, 0.017465597]\n",
      "(1, 0.96621668, 0.97680002)\n",
      "[1.0000161, 53.589352, 1.0000001, 2.8993292, 0.61447769, 0.057711288]\n",
      "(0, 0.97276664, 0.96560001)\n",
      "[1.0000155, 50.907948, 1.0000001, 2.7727158, 0.35719371, 0.013504178]\n",
      "(1, 0.95398331, 0.96929997)\n",
      "[1.0000141, 53.535816, 0.99999988, 2.7837546, 0.57549757, 0.053287953]\n",
      "(0, 0.9659, 0.95279998)\n",
      "[1.0000144, 50.791702, 1.0, 2.7702227, 0.36507368, 0.026313944]\n",
      "(1, 0.96573335, 0.9781)\n",
      "[1.0000142, 53.441376, 0.99999976, 2.7996135, 0.57351923, 0.056863114]\n",
      "(0, 0.96676666, 0.9562)\n",
      "[49.977379, 50.896122, 1.0000001, 2.6740358, 0.35973394, 0.033264384]\n",
      "(1, 0.96856666, 0.98019999)\n",
      "[1.0000168, 53.500027, 0.99999994, 2.6884382, 0.6053192, 0.057316579]\n",
      "(0, 0.97409999, 0.96759999)\n",
      "[49.969395, 50.965839, 0.99999982, 2.8945258, 0.38764057, 0.02953021]\n",
      "(1, 0.95756668, 0.9709)\n",
      "[1.0000172, 53.591854, 1.0000001, 2.8954461, 0.59503937, 0.060068466]\n",
      "(0, 0.96579999, 0.96039999)\n",
      "[1.0000163, 50.908932, 0.99999994, 2.8290977, 0.37228563, 0.031092858]\n",
      "(1, 0.96196669, 0.97530001)\n",
      "[1.0000154, 53.551823, 1.0, 2.8361523, 0.61943662, 0.06925603]\n",
      "(0, 0.97783333, 0.972)\n",
      "[49.958477, 50.911438, 0.99999976, 2.8338566, 0.36484751, 0.024191955]\n",
      "(1, 0.96789998, 0.98030001)\n",
      "[1.0000178, 53.4846, 0.99999982, 2.8413944, 0.6107111, 0.06164379]\n",
      "(0, 0.9738, 0.96569997)\n",
      "[49.981739, 50.889019, 0.99999994, 2.764425, 0.33854777, 0.026435502]\n",
      "(1, 0.96565002, 0.97920001)\n",
      "[1.0000162, 53.475494, 1.0000001, 2.7915831, 0.56703418, 0.056146566]\n",
      "(0, 0.96985, 0.9637)\n",
      "[1.0000166, 50.909264, 1.0000001, 2.7930882, 0.38082057, 0.03039542]\n",
      "(1, 0.96348333, 0.9738)\n",
      "[1.0000169, 53.54332, 1.0000001, 2.8047705, 0.59264946, 0.05726219]\n",
      "(0, 0.97606665, 0.96850002)\n",
      "[1.0000157, 50.879181, 1.0, 2.6625898, 0.35516223, 0.022289883]\n",
      "(1, 0.96743333, 0.97670001)\n",
      "[1.0000166, 53.51709, 0.99999988, 2.6704397, 0.56315482, 0.041939285]\n",
      "(0, 0.97358334, 0.96600002)\n",
      "[49.938293, 50.899349, 0.99999988, 2.8045113, 0.36469039, 0.031501845]\n",
      "(1, 0.96441668, 0.97539997)\n",
      "[1.0000176, 53.503609, 1.0000002, 2.8134789, 0.59520084, 0.059012093]\n",
      "(0, 0.97416669, 0.96509999)\n",
      "[49.934299, 50.902393, 0.99999946, 2.8538051, 0.36291036, 0.016406849]\n",
      "(1, 0.96155, 0.97570002)\n",
      "[1.0000138, 53.519924, 1.0000001, 2.8623972, 0.58922619, 0.054085795]\n",
      "(0, 0.97673333, 0.96799999)\n",
      "[49.98148, 50.8428, 0.99999988, 2.871573, 0.37053764, 0.031925946]\n",
      "(1, 0.95381665, 0.9734)\n",
      "[1.0000167, 53.441353, 0.99999976, 2.8924716, 0.58567637, 0.062839024]\n",
      "(0, 0.97479999, 0.96679997)\n",
      "[49.973293, 50.91021, 1.0000002, 2.8224945, 0.37661898, 0.037486248]\n",
      "(1, 0.96289998, 0.97670001)\n",
      "[1.00002, 53.505371, 1.0, 2.8220255, 0.62836474, 0.078432418]\n",
      "(0, 0.97718334, 0.96880001)\n",
      "[1.0000182, 50.858448, 1.0000001, 2.8898001, 0.36982989, 0.023196533]\n",
      "(1, 0.96026665, 0.97409999)\n",
      "[1.0000166, 53.494473, 1.0000001, 2.8843706, 0.5913288, 0.058508299]\n",
      "(0, 0.96886665, 0.96249998)\n",
      "[50.000179, 50.880085, 0.99999994, 2.7797565, 0.36600924, 0.025523931]\n",
      "(1, 0.9691, 0.9777)\n",
      "[1.0000161, 53.464817, 1.0, 2.8027086, 0.56046993, 0.046254572]\n",
      "(0, 0.97746664, 0.96850002)\n",
      "[49.945312, 50.875057, 1.0, 2.6802123, 0.37153935, 0.031189574]\n",
      "(1, 0.95486665, 0.97049999)\n",
      "[1.0000174, 53.505562, 0.9999997, 2.6939344, 0.56556177, 0.053118594]\n",
      "(0, 0.97201669, 0.96450001)\n",
      "[49.974472, 50.884235, 1.0, 2.7990813, 0.36775476, 0.018269742]\n",
      "(1, 0.96684998, 0.97850001)\n",
      "[1.0000169, 53.521572, 1.0000001, 2.8128562, 0.60259563, 0.048026178]\n",
      "(0, 0.96745002, 0.95929998)\n",
      "[1.0000142, 50.893742, 0.9999997, 2.7706735, 0.36303023, 0.017304901]\n",
      "(1, 0.95856667, 0.97229999)\n",
      "[1.0000166, 53.518299, 1.0000005, 2.7763581, 0.58267349, 0.05574888]\n",
      "(0, 0.96658331, 0.9594)\n",
      "[1.0000169, 50.900955, 0.99999994, 2.8199363, 0.38292295, 0.021487147]\n",
      "(1, 0.96534997, 0.9777)\n",
      "[1.0000198, 53.519127, 1.0000002, 2.8448427, 0.62231266, 0.057282262]\n",
      "(0, 0.97158331, 0.96520001)\n",
      "[1.0000142, 50.885605, 1.0, 2.7808688, 0.36702716, 0.029615184]\n",
      "(1, 0.96156669, 0.97539997)\n",
      "[1.0000188, 53.509956, 1.0000001, 2.7942939, 0.60482466, 0.05875013]\n",
      "(0, 0.97216666, 0.9648)\n",
      "[1.0000163, 50.883854, 0.9999997, 2.8466547, 0.3594318, 0.024551963]\n",
      "(1, 0.96378332, 0.97850001)\n",
      "[1.0000143, 53.471432, 1.0, 2.8544452, 0.57157904, 0.054036554]\n",
      "(0, 0.97176665, 0.96329999)\n",
      "[1.0000132, 50.866257, 1.0000001, 2.8640864, 0.35872853, 0.034733884]\n",
      "(1, 0.96301669, 0.97460002)\n",
      "[1.0000147, 53.479336, 1.0000001, 2.8921237, 0.5673995, 0.064091228]\n",
      "(0, 0.96761668, 0.9601)\n",
      "[1.0000162, 50.944897, 1.0, 2.9703588, 0.35505235, 0.0334078]\n",
      "(1, 0.9594667, 0.97500002)\n",
      "[1.0000135, 53.582108, 0.99999988, 2.9955289, 0.57659781, 0.06396661]\n",
      "(0, 0.96688336, 0.95840001)\n",
      "[49.910343, 50.823627, 1.0, 2.7429287, 0.37550095, 0.023924509]\n",
      "(1, 0.96305001, 0.97759998)\n",
      "[1.0000181, 53.475273, 1.0000002, 2.7562165, 0.6027801, 0.059689872]\n",
      "(0, 0.97096664, 0.96170002)\n",
      "[49.987122, 51.023598, 1.0, 2.8698938, 0.36229542, 0.023204727]\n",
      "(1, 0.95964998, 0.97210002)\n",
      "[1.0000144, 53.641632, 0.99999976, 2.8926907, 0.58490872, 0.062171027]\n",
      "(0, 0.96829998, 0.95920002)\n",
      "[49.98243, 50.908035, 0.99999994, 2.9160819, 0.35971338, 0.016034842]\n",
      "(1, 0.96016669, 0.97479999)\n",
      "[1.0000153, 53.546082, 0.99999994, 2.9173012, 0.58591342, 0.050657798]\n",
      "(0, 0.97293335, 0.96600002)\n",
      "[1.0000153, 50.916275, 0.99999976, 2.6384926, 0.37320498, 0.021340176]\n",
      "(1, 0.95021665, 0.96820003)\n",
      "[1.0000172, 53.518982, 1.0, 2.6464961, 0.56827497, 0.05794546]\n",
      "(0, 0.97416669, 0.96759999)\n",
      "[1.0000154, 50.912663, 1.0, 2.824563, 0.34654427, 0.020131141]\n",
      "(1, 0.96724999, 0.97640002)\n",
      "[1.0000166, 53.54187, 0.9999997, 2.8541772, 0.56463641, 0.051846799]\n",
      "(0, 0.97683334, 0.96939999)\n",
      "[1.0000181, 50.829094, 0.99999982, 2.9453177, 0.36336365, 0.022657612]\n",
      "(1, 0.95866668, 0.96990001)\n",
      "[1.0000166, 53.477966, 1.0000002, 2.9552281, 0.59471953, 0.052734748]\n",
      "(0, 0.97031665, 0.96420002)\n",
      "[1.0000162, 50.85844, 1.0000002, 2.7105918, 0.35948235, 0.025067057]\n",
      "(1, 0.96728331, 0.97850001)\n",
      "[1.0000136, 53.429028, 1.0, 2.7396498, 0.60187787, 0.061717246]\n",
      "(0, 0.97108334, 0.96469998)\n",
      "[1.0000138, 50.950661, 1.0, 2.7300141, 0.36362621, 0.018854691]\n",
      "(1, 0.95835, 0.97219998)\n",
      "[1.0000143, 53.548889, 1.0, 2.7258828, 0.58921623, 0.058547691]\n",
      "(0, 0.97348332, 0.96499997)\n",
      "[1.0000151, 50.876026, 1.0, 2.8384378, 0.36411962, 0.029090373]\n",
      "(1, 0.95873332, 0.97149998)\n",
      "[1.0000168, 53.538853, 1.0, 2.842608, 0.58548534, 0.058938589]\n",
      "(0, 0.96569997, 0.96060002)\n",
      "[1.0000174, 50.951996, 1.0, 2.6482937, 0.38034156, 0.030567726]\n",
      "(1, 0.96261668, 0.97549999)\n",
      "[1.0000197, 53.5434, 1.0000004, 2.656605, 0.59660399, 0.051807038]\n",
      "(0, 0.96915001, 0.95999998)\n",
      "[1.0000147, 50.877411, 1.0000001, 2.8855977, 0.35588226, 0.020556688]\n",
      "(1, 0.96485001, 0.98030001)\n",
      "[1.0000184, 53.486538, 1.0, 2.8832166, 0.5827474, 0.056628235]\n",
      "(0, 0.97111666, 0.96240002)\n",
      "[49.950974, 50.898388, 0.99999976, 2.8902209, 0.36267099, 0.02657065]\n",
      "(1, 0.96759999, 0.97890002)\n",
      "[1.0000187, 53.501606, 1.0000001, 2.8868482, 0.56380886, 0.054169957]\n",
      "(0, 0.9655, 0.95779997)\n",
      "[1.0000172, 50.912449, 0.99999994, 2.975903, 0.3757343, 0.024124507]\n",
      "(1, 0.94778335, 0.96859998)\n",
      "[1.0000184, 53.477219, 0.99999982, 2.9857862, 0.63630509, 0.060558025]\n"
     ]
    }
   ],
   "source": [
    "test_accuracies = []\n",
    "train_accuracies = []\n",
    "norms = []\n",
    "\n",
    "for i in range(100):\n",
    "    alignmnist = AlignMNIST()\n",
    "    train_op = tf.contrib.layers.optimize_loss(cost, global_step=gs, learning_rate=lr,optimizer=\"RMSProp\")\n",
    "    max_norm_op = max_norm_constraint(weights, biases)\n",
    "\n",
    "    pred = tf.equal(tf.argmax(mlp, 1), tf.argmax(y, 1)) # Count correct predictions\n",
    "    train_acc_op = tf.reduce_mean(tf.cast(pred, \"float\"))  # Cast boolean to float to average\n",
    "    #tf.scalar_summary(\"training accuracy\", train_acc_op)\n",
    "\n",
    "    test_pred = tf.equal(tf.argmax(mlp_test, 1), tf.argmax(yt, 1)) # Count correct predictions\n",
    "    test_acc_op = tf.reduce_mean(tf.cast(test_pred, \"float\"))  # Cast boolean to float to average\n",
    "    #tf.scalar_summary(\"test 0 accuracy\", test_acc_op)\n",
    "\n",
    "    #writer = tf.train.SummaryWriter(\"./logs/{0}\".format(logfile), sess.graph) # for 0.8\n",
    "    #merged = tf.merge_all_summaries()\n",
    "          \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        tf.initialize_all_variables().run()\n",
    "\n",
    "    # create a log writer. run 'tensorboard --logdir=./logs/{logfile}'\n",
    "   \n",
    "        sess.run(max_norm_op)\n",
    "\n",
    "        for epoch in range(2):\n",
    "            trX, trY = alignmnist.next_epoch()\n",
    "\n",
    "            for start, end in zip(range(0, len(trX), batch_size), range(batch_size, len(trX), batch_size)):\n",
    "                sess.run(train_op, feed_dict={x: trX[start:end], y: trY[start:end]})\n",
    "\n",
    "            sess.run(max_norm_op)\n",
    "\n",
    "\n",
    "            trn_acc, tst_acc = sess.run([train_acc_op, test_acc_op], feed_dict={x: trX, y: trY, xt: teX_0, yt: teY_0})\n",
    "            #writer.add_summary(summary, epoch)  \n",
    "\n",
    "\n",
    "            print(epoch, trn_acc, tst_acc)\n",
    "            train_accuracies.append(trn_acc)\n",
    "            test_accuracies.append(tst_acc)\n",
    "\n",
    "            nrms= [np.linalg.norm(weights['h1'].eval()),np.linalg.norm(weights['h2'].eval()), np.linalg.norm(weights['out'].eval()), np.linalg.norm(biases['b1'].eval()),np.linalg.norm(biases['b2'].eval()),np.linalg.norm(biases['out'].eval())]\n",
    "            print nrms\n",
    "            norms.append(nrms)\n",
    "            writer.flush()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-17T06:31:13.008821",
     "start_time": "2016-06-17T06:31:10.564576"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlesmartin14/anaconda2/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-17T06:31:15.046693",
     "start_time": "2016-06-17T06:31:14.864873"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x15909c4d0>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEACAYAAAC9Gb03AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XlYVdX+BvD3C4ozIKiIs4KiqThPqYnzkKVl5Vg3LX/m\nzbppqXW7pWWlZmnlUGpazpamaeZsUs6z4AyigAqCioCiIsr398fGE4cDMh1Bd+/neXg8e1p7nS28\ne+211z5HVBVERGReDvldASIierAY9EREJsegJyIyOQY9EZHJMeiJiEyOQU9EZHKZBr2IzBGRKBEJ\nvM8634hIsIgcFpH69q0iERHlRlZa9D8A6JzRQhHpCsBLVasDGALgOzvVjYiI7CDToFfV7QCu3meV\nHgDmp6y7B4CLiHjYp3pERJRb9uijLw/gXKrpCynziIjoIcCbsUREJlfADmVcAFAx1XSFlHk2RIQf\nrENElAOqKjndNqstekn5Sc9qAC8BgIg0BxCrqlEZFaSq/LHTz5gxY/K9Dmb64fHksXxYf3Ir0xa9\niCwG4AfAXUTCAYwB4GRkts5S1bUi0k1ETgNIADAw17UiIiK7yTToVbVfFtYZZp/qZM2JSyfgU8oH\nDuKAned2wrmQM+qUqQNVxfn486joUtFmm5ibMVBVuBd1v2/Zx6KPISk5CfXLGo8D3Ei6gaIFi9qs\ndynhEmJvxaK6e3X7vKn7UFWIiOV1fGI8XAq7PPD9EpE55PnN2NDYUFxLvAYAuJt8F9EJ0QCMAPvp\n6E9IuJ0AADgXdw5XbxqjOree3YrBqwcjWZNx6vIp+H7ni4///Bjn4s6h++LueGPdGwCAeQHzUGt6\nLYTHhUNVMT9gPuIT4wEAL618CW3ntUXC7QQcijyE0ZtGW+o0ftt4/B70O05ePgm/eX4YsmYIAGDP\n+T0oM6kMjl86DgDYfGYzrt68ClXFS7++hI4LOuL67etIupuEn4/9jJtJNwEAV25cQbImZ3osUl+S\nRVyLwNrgtQCA67evY9CqQZZjMXDVQIz7cxwA4IOtH6Dl3JZQVfj5+eFAxIF0L+1WnVyFLgu7WJZ9\ns+cby3Fff3o9dp/fnWn9/mn8/PzyuwqmwWP5cBF79P9keWci6jrBFd2qd8OiZxfhw60fYsruKfj5\nuZ+xJmgNlp9YDo9iHuhbpy8m7ZwE18KumNhhIl5f+zrcirjhP83+g/Uh6+FdsgZ+Pr4URQoUwbPe\nL2Hh8VlY0Wc5BqwYAJ9SPlBVtKzYEh/9+REG+A7Aqw1fxQvLXkDryq1x+cZlHL54GNcSr+H8iPMo\nUqAISn9eBmVLeCA6IRqTO0/GuL/GYWXvlRi/bSICz1xEIZer6Fe3Hz756xPUK1sPbzZ9Ex/8MRY+\nzg1QpYw7Iq5H4EDEAYgI6petjzVBa/BOi3cwvsN4BF0JwvFLx9HDpwfC48Lx1e6vMK7dOBQuUBid\nF3bGoPqD0N+3P4atHYaZB2Zi56Cd+PHwj/j+0Pf4qvNX6FGzB3y+qY1iBYvircffwFe7v0KRgkWw\npNcSOBdyRu0ZtbGu/zp08e5iOc5R16Pg+2093ElywIp+SwAAfvP8MLHDRAxvPhzeU73Rvmp7zO0x\nF3eS72DLmS3w9fCFZwnPPPtdIKKsExFoLm7G5nnQf7F+Mb4+9h5GtnwbH//1MaZ0mIHhm/8Nr5Je\n6BG/EUWbL8SWsPWY1HES9kfsx+DfBmP2U7NR260h/Ba2QMnCJZE87QQ+/+Eo/or/AZcXTMUl7yk4\n7f41PItWwpOX/8DPJRvi2u1rWNptI/qu7YwCDgXwWt3ReMarP97a0RuDG7yGz7dOx/A2r8ClsAue\nmvwhZj6+Bd6tD+HMn4/j54uf4o7nDuwI24Nr40LRc+6rOHblMHonbsJh9/ewJmwJOkdvwM2zDXCs\nbS00KNMURVavwOvjdyH8+mm0qtAW7Rc+gXdbvovx28ejaMGi8CnlgwMRB1C1ZFWULV4WvmV8sfTY\nUgDAvsH7UOWrKviwzYeYuGMiHMURztun447fKPTz7YvZi6PQyu05LCvSET8/vwxHI4Jx4UYIbiff\nxrHoY3Ar4oaNL27EuuB12HRmE3ad3wX3+HbYua4inhi0HtdvX0fBq3VwOOknfNz2Y3y67VMUKVgE\nJ14/gd+Dfse/fv0XFIq4W3FwcnTCqWGn0u3+IqL8kdugz+s7x1qjhmq/j1YpxkIHz5qhdeuqRsRH\n6rbd1xVQXbxYVVV19GjV6dNVbybd1LlzVWvXVl0QsFCn/LpFAdX331e9cUO1WDHVVu3j1HWCq77z\n3Xp1cFDdE3RGT0aGqqur6pRft2iz2c30pZdva48eRtkrVqgW7fCFvrZmqL6z/l1Fu/9p166qycmq\nNWqoNu8QqQU+LqBtx7+tgOqatbc1NiFBixdX7d0vUZccXK2urqrFi6sevxCmc+ffUkB13jzVpCRV\nX1/V92ZvUqdxTvrhz0v104k3deL2ibr17Fa9lXRLW85pqe4T3fVg8AVtOquZdlvUTZ9a1ENDQ1U/\n+fMT/WTxZgWS1XtSAy00rpAWrhygvr6q4bHhumCBapN2F9RlvIu6TXTTU+ej1PMLT52+d7qW/ry0\nTtg2Qafumap9ByQqCiao+4RSWmlyZXV0uq1NJndXp3FOOmbh71pkXHGNuRGjb617Sz/e+qkmJyfr\n7Tu39bHpj+nRqKNKRA8PI6pzkb252TjbOwO0aFHVdu1U1wWv08H/d1cB1a1bVYcNU23QQLV9e9XI\nSFVXV1V3d9WTJ1XLlVMtVUp1717VkSNVu3ZVrV5ddeVKY5sSJVRjEuJ0yBDVIkVUp05VXbRIVUR1\n1CgjwMuWNU4KERGqXbqoouxB9ZpSQ+t83UQ9mm1VV1djG29vY72Z+77X5wdGaoUKxknlr79Ua9Uy\n6jFihOpzzxnvY9Uq1WeeUe3dW7V+fdWZM1VLl1Z94gnV64nXtW1bo7y4uL//02JuxGhg5DGtXl11\nyJSVirHQN79Zr1WrGieKQYOMMp4b85M2n95Ra9RQLVlS9cIF1Y4dVZ2cVJ9a1ENHrn9PS5RQHfHr\nOHX8yFE3nt6oqsb7LVdOtWpV1Td+/E4/XvaLAqpPvbZXey7pqXXqJmuF9/10ffB69Z5cR8s22qM3\nbhh1qzujrgZeDLTTrycR2UNugz7Pu26mT1eMHg1cvgzUrg20bw9ERgK7dgHbtwMtWwKdOgFubsbP\n9OlA165A9erAlSvApk3A/PlA796AiwsweDDw9dfA8uVA377A888b6xQpAtSta7xeuNCY36YN4Oho\nrFvNKxknny6N28mJ6HToCtxdCmHZMmDiRGDGDGObAQOAl14C1q41tr19GyhUCPj4Y6PcgADg8GFg\n9WogJAR44gkgPNxY1rMnMHs28H//BzRvDnTsCHTrBgwaBPz4I7BjBzBwIPBC72S0/s/32DH1VSxZ\n7IC5c4Hhw419LF8OPNsrGQcPOCA+HmjUyKhfuXLA9Jk3kZxUCO3bOWDWDwmo3T4ATlGPw9kZSE4G\nOncGXngBcHUFHByA/fuBbduM99KkCeA15D107B6L+YeW4saYy5gy2RFvvQXU/64+fuz5o2XUERHl\nv0eu6yYxUbVxY9WFC41Wa2ys0QXStq1x5nrjDVUHB9WQENWEBNWnnlINC1MNDjbWK1tW9e5do2tH\nxGihDxigOmmSsTwhwbgScHc3XpcqpTp0qFHunj3GNcwbb6i+/rqq7ye91GtsJ333XVV/f6PlHRtr\ntKg//9y4Orh82ZjfoIHq5s3G9NChRh1OnDDq0K6dUfelS42yVVXfftu40nj/fdU//jCuBho2NK5Y\nfH2N6SlTVL28jPWrV1cdP964kmncWPXqVeP99OmjOmuW6uzZRn1eftm4+vniC9X//U+1TBnVV181\nymjVyij3iy9UBw406tOzp+qTT6ouW2a8hyZNjCuQ8u1/VadxTlpzzDP61FPGcU1IUG3wXQM9EHEg\n1y0QIrIfPGpdN6qq77xj9IX37m28iYkTVdeuNV6fPm0EVXpatFB95RXj9cmTRlirGl01lSr9HbhD\nh6q++abxun9/48Tx++9Gl8YLLxgB/d13ql2GbtY2g3/TefOMdaOijH9nzVKtVk21aVNjumFD1cKF\nVW/etK5PcrLRPTJtmm1djx9XLVhQNTzcWM/Hx9h3crIRzM2bGycLV1fVo0dVXVyMbps6dYzAV1Wt\nV8/opjlyxCgHME42ixap9uql+vjjxrGqUUP14kWjjJ49VQsVUl2wwDiWFSqourkZ3T4ffWSUERio\nWsjtomIstPHQaTpvnlHe5MmqjWc11n0X9qX/H0BE+eKRDPo1a4w9z5yZvTd7+LDq2bO28/fuNcr7\n4ANjOjHRCE1VIxQLFTJaq6lt3260bhs0MFr6qQUGGuUNHWpM/+c/qp06pV+nwEC19G+ndfny36/P\nn//7RJGc/Pc2XboYJ6+OHY3pyEij/qrG1UGJEqp37hjTK1car8+eNa5UihVTvXbNOFl88olxIrl0\nybgiiIw09uPqqlqlirF9cPDfVxyenqqNZjyudduc1p07jfpdvaradHZT3XM+zQEhonz1SAZ9bKyq\no6MRPPaQmGi0fNevt10WH6+WFntqsbFGUBYtarxO7c4dI2DnzDGmg4ONk8mD8NFHRt3HjLFdtnq1\n0e2S1r2by35+xnS3bkZ9741YSq19e+OqJq3WrVW3bDGuAi5d+nt+8++b687wnTl6L0T0YOQ26O3x\n6ZXZ5uICHDkCeHvbpzwnJ+PG5xNP2C4rUcK4oZpeHdzdgTt3jNepOToCb78NdOhgTNurnul5/HHj\nJm+LFrbLunc3buCmJWLctK5Xz5h+4gnjBnB66/bpA5QpYzvfywvYs8coyz3Vp0I4imOWnuolokdH\nvgQ9ANSqZd/y0gvzzNSpA9y6lf6yMWNyV5+satoUKF4caNbMdpmIcdJJz9SpxnYA8NRTwMWLtics\nAHj11fS39/YG1q0zRjNJqnv5DuLAoCcymX/0F4/4+gKPPZa/dXB2BiIijGGQ2eHpaVytAMZ7mDIl\ne9t7eQE7dxpBn5qDOOCu3s1eYUT0UMu3Fv3DYNQo4O5DkGn3AjsveXsb7z29oGeLnshc/tFBX7Jk\nftcg/3h5Gf/WqGE939GBffREZvOP7rr5JytZ0njymC16IvNj0P+DLV8ONGhgPc9BHHA3+SHozyIi\nu/lHd93807VtazuPwyuJzIcterLCrhsi82HQkxUOryQyHwY9WWGLnsh8GPRkhcMricyHQU9WOOqG\nyHwY9GSFXTdE5sOgJyscXklkPgx6ssIWPZH5MOjJCodXEpkPg56ssEVPZD4MerLCPnoi82HQkxUO\nryQyHwY9WWHXDZH5MOjJCp+MJTIfBj1Z4agbIvNh0JMVdt0QmQ+Dnqxw1A2R+TDoyQpb9ETmk6Wg\nF5EuInJSRIJEZHQ6y51FZLWIHBaRIyLyst1rSnmCwyuJzCfToBcRBwDTAHQGUBtAXxGpmWa11wEc\nU9X6ANoC+FJE+H20jyC26InMJyst+qYAglU1TFWTACwF0CPNOgqgRMrrEgCuqOod+1WT8gqHVxKZ\nT1aCvjyAc6mmz6fMS20agMdEJAJAAID/2Kd6lNc4vJLIfOzVvdIZwCFVbSciXgA2iYivql5Pu+LY\nsWMtr/38/ODn52enKpA9sOuGKP/5+/vD39/fbuVlJegvAKiUarpCyrzUBgIYDwCqGiIiZwHUBLA/\nbWGpg54ePo7iiKTkpPyuBtE/WtpG8EcffZSr8rLSdbMPgLeIVBYRJwB9AKxOs04YgA4AICIeAGoA\nOJOrmlG+4KgbIvPJtEWvqndFZBiAjTBODHNU9YSIDDEW6ywAnwD4UUQCUzYbpaoxD6zW9MCw64bI\nfLLUR6+q6wH4pJk3M9XrSBj99PSIY9ATmQ+fjCUrHF5JZD4MerLC4ZVE5sOgJyvsuiEyHwY9WeGn\nVxKZD4OerHB4JZH5MOjJCrtuiMyHQU9WGPRE5sOgJyscXklkPgx6ssLhlUTmw6AnK+y6ITIfBj1Z\n4fBKIvNh0JMVdt0QmQ+Dnqyw64bIfBj0ZIWjbojMh0FPVvhkLJH5MOjJCrtuiMyHQU9WGPRE5sOg\nJyscXklkPgx6ssLhlUTmw6AnK+y6ITIfBj1Z4fBKIvNh0JMVDq8kMh8GPVlh1w2R+TDoyQqDnsh8\nGPRkxVEcOeqGyGQY9GSFLXoi82HQkxUGPZH5MOjJCodXEpkPg56scHglkfkw6MkKu26IzIdBT1YY\n9ETmw6AnKxxeSWQ+DHqywhY9kfkw6MkKg57IfBj0ZMXRwZGjbohMJktBLyJdROSkiASJyOgM1vET\nkUMiclREttq3mpRX2KInMp8Cma0gIg4ApgFoDyACwD4RWaWqJ1Ot4wJgOoBOqnpBREo9qArTg8Wg\nJzKfrLTomwIIVtUwVU0CsBRAjzTr9APwi6peAABVvWzfalJe4XfGEplPVoK+PIBzqabPp8xLrQYA\nNxHZKiL7RORFe1WQ8ha/M5bIfDLtuslGOQ0BtANQDMAuEdmlqqftVD7lEXbdEJlPVoL+AoBKqaYr\npMxL7TyAy6p6C8AtEfkLQD0ANkE/duxYy2s/Pz/4+fllr8b0QDHoifKfv78//P397VaeqOr9VxBx\nBHAKxs3YSAB7AfRV1ROp1qkJYCqALgAKAdgDoLeqHk9Tlma2P8pf0QnRqDOjDqJHRud3VYgohYhA\nVSWn22faolfVuyIyDMBGGH36c1T1hIgMMRbrLFU9KSIbAAQCuAtgVtqQp0cDW/RE5pNpi96uO2OL\n/qEXczMG3t94I2Z0TH5XhYhS5LZFzydjyQo/1IzIfBj0ZIVdN0Tmw6AnKwx6IvNh0JMVBj2R+TDo\nyQo/vZLIfBj0ZIUteiLzYdCTFQY9kfkw6MmKgzhAoeDzDkTmwaAnG2zVE5kLg55sMOiJzIVBTzb4\n5SNE5sKgJxv88hEic2HQkw123RCZC4OebDDoicyFQU82+HQskbkw6MkGW/RE5sKgJxsMeiJzYdCT\nDX75CJG5MOjJBlv0RObCoCcbDHoic2HQkw0GPZG5MOjJBodXEpkLg55ssEVPZC4MerLBoCcyFwY9\n2eDwSiJzYdCTDbboicyFQU82GPRE5sKgJxsO4sBRN0QmwqAnG44O/IYpIjNh0JMNdt0QmQuDnmww\n6InMhUFPNji8kshcGPRkgy16InNh0JMNBj2RuTDoyQY/1IzIXBj0ZIMteiJzyVLQi0gXETkpIkEi\nMvo+6zURkSQRedZ+VaS8xqAnMpdMg15EHABMA9AZQG0AfUWkZgbrTQCwwd6VpLzlIA4cdUNkIllp\n0TcFEKyqYaqaBGApgB7prPcGgOUAou1YP8oHjsInY4nMJCtBXx7AuVTT51PmWYhIOQA9VfVbAGK/\n6lF+YNcNkbnY62bsVwBS990z7B9hDHoicymQhXUuAKiUarpCyrzUGgNYKiICoBSAriKSpKqr0xY2\nduxYy2s/Pz/4+flls8r0oHF4JVH+8vf3h7+/v93KE1W9/woijgBOAWgPIBLAXgB9VfVEBuv/AOA3\nVV2RzjLNbH+U/5756Rm85PsSnqn1TH5XhYgAiAhUNcc9JZm26FX1rogMA7ARRlfPHFU9ISJDjMU6\nK+0mOa0MPRzYdUNkLlnpuoGqrgfgk2bezAzWHWSHelE+4vBKInPhk7Fkg8MricyFQU822HVDZC4M\nerLBoCcyFwY92eDwSiJzYdCTDbboicyFQU82HMCgJzITBj3Z4PBKInNh0JMNRwcOryQyEwY92WAf\nPZG5MOjJhoM4cNQNkYkw6MkGn4wlMhcGPdlg1w2RuTDoyQaDnshcGPRkw9HBkcMriUyEQU822KIn\nMhcGPdlg0BOZC4OebHB4JZG5MOjJBodXEpkLg55ssOuGyFwY9GSDH2pGZC4MerLBDzUjMhcGPdlg\n1w2RuTDoyQaDnshcGPRkg8MricyFQU82OLySyFwY9GSDXTdE5sKgJxscXklkLgx6ssHhlUTmwqAn\nG+y6ITIXBj3Z4KgbInNh0JMNjrohMhcGPdlwEAckg0FPZBYMerLBPnoic2HQkw320ROZC4OebHB4\nJZG5MOjJBrtuiMwlS0EvIl1E5KSIBInI6HSW9xORgJSf7SJS1/5VpbzCJ2OJzCXToBcRBwDTAHQG\nUBtAXxGpmWa1MwCeUNV6AD4BMNveFaW8w+GVROaSlRZ9UwDBqhqmqkkAlgLokXoFVd2tqnEpk7sB\nlLdvNSkvseuGyFyyEvTlAZxLNX0e9w/yVwGsy02lKH9x1A2RuRSwZ2Ei0hbAQACtMlpn7Nixltd+\nfn7w8/OzZxXIDtiiJ8pf/v7+8Pf3t1t5oqr3X0GkOYCxqtolZfpdAKqqE9Os5wvgFwBdVDUkg7I0\ns/1R/lsbvBbT9k7D2v5r87sqRARARKCqktPts9J1sw+At4hUFhEnAH0ArE5TiUowQv7FjEKeHh1s\n0ROZS6ZdN6p6V0SGAdgI48QwR1VPiMgQY7HOAvABADcAM0REACSpatMHWXF6cDi8kshcstRHr6rr\nAfikmTcz1evBAAbbt2qUXzi8kshc+GQs2WDXDZG5MOjJBodXEpkLg55ssEVPZC4MerLBT68kMhcG\nPdlgi57IXBj0ZIPDK4nMxa4fgUDmwOGV2ZesydhyZguSkpPQuFxjlClWJr+rRGTBoCcb7LrJvgMR\nB9B7eW+Udy6PtlXa4puu3+R3lYgs2HVDNji8MvtOXTmFTl6d8GWnL3Ek+kh+V8dUohOiUerzUigx\nvgQ+2/ZZflcnT3y1+ysMXTMU4/4cZ5fyGPRkw9HBEddvX8e+C/sQnxifozKirkdhQcACLApchBtJ\nN+xcQ2sjNoyA83hnlJ9cHgm3Ex7ovjISdCUINdxroG6ZujgSdQRm/PC+a4nXMH3vdHyz5xucvXo2\nz/Z7NPooapaqiWldp+HQxUN5tt/8knQ3Ce//8T5ql6mNGu417FImg55seBTzgGcJT7yw/AWM2Tom\nR2X8cPgHTNo5CWP/HItfT/5q5xpa23luJ5a/sBylipbCsUvH7Fq2qiI0NhQhMSH3vcoJjglGDfca\nKFu8LBSKqISoDMv7K+wvbArZhKjr6a8DADE3Y1D5q8ooPak03lz3Zo7qvilkE2pOqwmfaT5Yf3p9\njspIbWvoVkzZPQX7I/aj08JOuHrzaq7LzIrgK8GoWaomvN28cSH+Qp7sMz8dv3QcFZ0rYljTYehd\np7ddymTQk43SxUpjx6Ad+KHHD9hzYU+OygiPC8fghoPx78b/xrawbXauobXTMafh6+GLeh71cCQq\nZ90m28O3Y1HgIhy+eNhqvn+oP+rMqIMWc1rg/T/ez3D7oCtBqO5WHSJiadWn59SVU+i+uDuGbxiO\nMf4Zn0R3hO+AV0kvHPy/g1hxYgV2nduVrfejqhi1eRRGtxyNMW3GYPiG4bnujguPC0cnr06Y/8x8\nPFn9STy/7HksClyEAxEHclVuZu5dLVVwroDz8ecf6L4eBgciD6BxucZ2LZNBTxlq5NkIAVEBSLqb\nlO1tz8WfQ0WXimhduTW2hT+4oI+9FYtbd27Bo5gHfD18ERgVmO0yLiVcQrdF3bA6aDW6LOxiFYhr\ng9di5OMj8efLf2J+wPx0w1JVjaB3rw4AqFOmDo5GH013X0FXgtC6cmt82elLhFzN+BO9t4dvR5vK\nbVDRpSImdpiIN9a9gdhbsbiZdDNL7+m3oN8AAC/Xfxl96/RFmWJlsDBwYZa2zUhYbBgquVQCAEzq\nOAkNyjbA78G/P/DWfXBMMKq7VYdnCU9cvH7R9PePDkQcQCPPRnYtk0FPGSpRqASqulbNMLTu51zc\nOVR0roj6ZesjPC4cV25ceQA1BEJiQuDt5g0Rga+Hb45uhP507Cc85fMUfnruJ3gU98Cu83+3njeE\nbEAX7y6oVboWypUoh62hW222j0qIQuECheFWxA0AjBZ9BvUIvmKEVrWS1XDm6pkM67Tj3A60qmR8\nUVu/uv1QtnhZS1fO//74Hy7fuIxriddstvsr7C9M2jEJ7215Dx8+8SFEBCKCz9p9htGbR6PP8j6Y\ndWBWto7PPWFxYajsUhkAUNCxICZ1moTFvRajh08PfL3n6xyVmRX3WvROjk5wK+KWYbdYfgmNDUXn\nhZ3RZHYTvLv53VyXtz9yP1v0lLealm+KvRf2Znu7ey36Ag4F0KxCM+w4t+MB1M7otvF28wZgBGxg\nVKDVjdAlR5bgi51fYFPIpgzLWBC4AC/6vggAeLbms1hxYgUA4EL8BURci7D80fWv2z/dVvG9ILqn\nrkfdDE+O91qnlV0r43z8edxJvmOzzq07t3Do4iE0q9AMgPHtQmv6rUHcu3E4OewkQq6GoNrX1eD2\nuZtN3/uHWz/EoYuH8K96/0KPmj0s81tWaolFzy5Cq0qtcjxyJTwuHJVdK9vM/2/r/2La3mmIuxWX\no3Lv507yHYTGhsLLzQsAbLpvFgQsQJFPi6DYZ8WwPXx7rvd3LfEaVp5YiZUnVt736inxTiJWnVyF\nBQEL0HJuS3So2gFTu07F7IOzcS7uXIbbZSbpbhKORh9FA88GOS4jPQx6uq8m5ZpkO+hvJN1Awu0E\nlC5aGgDQulLrB9ZPfzrmNLxKGiFQtnhZiAguXr8IADh88TCGbxiOyGuR6LeiHwIuBthsH3QlCGGx\nYehQrQMAoNdjvbDixAqoKjaEbECHah3g6OAIAOhTpw9+Pfkrxm8bbzkZ3Cujult1y3Tt0rVx/NLx\ndJ9FOB1zGtXdq8PJ0Qlli5dNNxQORBxAzVI1UdypuM2yCs4VsKTXEsS/F4/Xm7yOY9HWN59Drobg\n03afYlTLUXAQ6z/v9tXa4/Umr+PWnVs5GjUTFvd3101q3m7e6FmzJ8pNLgfPLz1zdAWYkfC4cHgU\n90DhAoUBGO8/9Q3ZbeHb8Fm7z/B2i7ftctN/QeACjNo8CmP8x9z3hDhh+wS8/8f7WHlyJWZ0m4GR\nLUeieYXm6FenH2YfnJ3j/R+/dByVXSqn+3+fGwx6uq+m5Ztib0T6QX/x+kW0mNMCdb+ti+/2f2eZ\nfy7uHCqvzWLgAAAQ1klEQVQ4V4DxZWNG0K87vQ7Lji2z+820kKshlhb9vRuh9/rpp+6ZijebvYkv\nO3+JyZ0mo/+K/ohOiEZYbBgmbp+IJxc/ied+fg596/RFAQfj2cHapWvDydEJvwX9hpUnV6KLdxfL\nvjxLeOKbrt8gPjEew9YOs7Qgg68EW7XoXQq7wL2oO3ou7Yn3t1jfwA2OCbbUN6Pum+3h29GqYqtM\n37u3mzdOx5y2TN+6cwvRCdGo6FIxw21EBG2rtsUfZ//ItPzUbt25hZibMfAs7pnu8llPzULEiAiM\naD4C7215L1tl30/aq6W0Lfoj0UfQqFwjdK/RHetOr8uwnL/C/kKLOS3Qam6r+97H2XluJ0a3HI2l\nzy3FnENz0r0/FZ8Yj2n7pmFF7xVY0XuF1ZXTa41fw/cHv8/wvtbByINYG7wWpy6fspqfrMnYFrYN\nS44uQaNy9u2fBxj0lIm6HnVx5uoZ/HH2D4TEWN88XBS4CJVdKmNYk2H45cQvlvn3um3uaVGxBRqV\na4QZ+2fg1dWv2rV+qbtuAFj66S/fuIwVJ1dgcEPji88G+A5As/LN4DPNB01mN8GpK6cwuOFgTOgw\nAZ+2/9SyvYhgRIsRGLlpJEJjQ9HVu6vV/l6q9xLGdxiP6d2m45XVr+Bm0k0ExQTZjHde/vxyDPAd\ngGn7plnuT9y6cwtR16MsreJqrtZB/2fon3hy8ZOYtm8aWlZqmel793bzxumrfwd9aGwoKrlUspy0\nMtK2Stt07zXcz/n48yhXopzl6iYtB3GAS2EXvNnsTRyNPoq/wv7KVvkZuXdP457yJcpbgj5Zk3E0\n+ijqlqmLxuUaIzohGuFx4emWs+TIErSs2BINyjbAnINzMtzfrvO70KJCCzxW+jF4u3lj9anVNut8\nu+9bdKzWMd0x7rXL1Ia3mzc6L+yMfr/0s+r+UVX4/eiHqXunotUPrazuW323/zu8uPJF7I/Yjz61\n+2R+YLJLVfPsx9gdPWreXPumtprbSktOKKkX4i9Y5tf7tp5uPbtVI69FqusEV01OTlZV1bkH5+qL\nK160KSf2ZqwW/6y4Xku8Zre6eX7hqeGx4ZbpOQfnaL1v62nXhV114K8D7baf9PT7pZ+W+KyEFvi4\ngB6PPp7uOt0Xd9elR5aqqurRqKPqM9XHsuyTPz/Rdze9a5nu/0t/HbF+hK4NWquJdxIz3X/wlWCt\n8lUVy/SaU2u084LOWdqu3JflLP9fWbE5ZLO2+aFNltZdFLhIS04oqbWm1dIFAQuyvI+d4Tt1ceBi\nXR+8Xu8m31VV1WG/D9PJOydb1pl/eL72+6WfqqqGxIRohckVLMv6/dJPZ+6fmW7ZPlN99FDkIQ28\nGKiVp1RO971HXY9S1wmuln0vClykT/zwhB6MOKgLAxZq2x/bqtfXXlr8s+J6JOpIhu/jfNx5XXF8\nhdaYWkN3n9ttmR96NVQ9v/BUVdXXfntNR6wfoaqq8bfi1WOShx6MOJhhmSnZmePs5WfdUKa+7mqM\nqBi9aTTGbB2D2U/PxpGoI7hy8wqeqPwEHMQBxZ2K48zVM/By8zJa9M623QcuhV3QtHxTbDmzxepy\nN6cSbifg6q2rKO9c3jKvh08PxN6Khaqiv2//XO/jfhY8swBXb15FAYcCcCnsku46nap1woaQDehd\np7fN1Ue1ktXw6ymjXzlZk7ExZCP2Dt6LKq5VsrT/yi6VEXEtAol3ElGoQCGEXA2x3K+4H6+SXnAQ\nB+w6vwuPlX4MroVdM90moxux6elXtx+alm+KzWc2Y17APAzwHZDpNr8H/Y5XVr+CtlXbIuhKEEZt\nHoXnH3seW85useo+S911cyTqCHw9fC3Lunp3xbLjy9C3Tl8UcypmuUcRcS0Cl25cgq+HLwQCB3FA\nYFQg6pWtZ1WHXed2oVn5ZpbtetXqhfkB8zFo9SCUK1EO/27yb9QvWx/FnYqjbPGyGb6X8s7l8Yzz\nM1gdtBoBUQGWm+rHLh1DnTJ1AABj/Mag9oza6OLdBWuC1qCTVye734BNjUFPWfZe6/dQY2oN9Drd\nC6tOrkL/uv0tfxRNyjXB/oj9RtDHncuwn7F79e74Pfh3uwT9matnUK1kNaubju5F3TGixYhcl50V\nDuIA96Lu912ns3dnTNwxEapqGXFzT+o++sMXD6NkkZJZDnnAGOJY0bkiQmND4VPKByExIZbRKfcj\nIuhbpy96/dwLCbcTcGTokUxDPCwuDJWcbW/EZsTbzRtlipXByE0jkXA7AcWcitmsc/vubSwIWICr\nt65i4o6J+K3vb2heoTlUFb8F/Ybd53ejV61eVt1YqW/GBkYFom6ZupZlnb064+2Nb8PjCw90qNYB\nq/qsgohg69mtaFO5jeX3pIdPD6w6tco26FO6be4pVKAQ1g/I+RPFvmWsn+s4Gn0UtUvXBmAMHPi0\n3af47x//RdGCRbHgmQU53k9WsI+essy1sCu+7PQlRm0ahf2R+/Fqw7/72xuXa4z9EfsBIMMWPQB0\nr2EEvabzWTDJmozpe6dj3J/j4B/qn2E9riVeQ7Wvq6HJ7CaWFtLDqrpbdRR0LIjjl44b/c3u6Qf9\nhtMb0Nmrc7bLT31D9kysceLLis87fo7ItyPxUr2X8OPhHzNdPywuLMst+nucCzmjkWejDP8vlx5d\nism7JyMsNgxLei1B8wrNARgnoqd9nsZn7T/DuHbjrK44yjuXx4VrF6CqOBJt3aIvXaw0ot6JQuy7\nsQiOCbY8NLY1dCvaVW1nWa9HzR5YenQpFgUuMj5aOuXG6a7zu9Ci4t9Bn1v1ytazCvrULXrAuHG7\nb/A+/Pnyn+mOZrInBj1ly4v1XkTg0EDsG7zPqhuicbnG2B+ZKugzGPlR3b06ihUshqeXPo231r9l\nNQRxy5ktmLJ7Cm4k3cDzy563DJNM65cTv6B2mdq4MuoKFj+72I7vzv5EBJ2qdcKwdcOwPmS91TEr\nVbQUbt+9jdhbsZYHs7IrddCHxGSt6ya1Vxq8gh8O/5Dpx1KHx4XnKIy6enfN8HN2Zh+cjU/bfYqp\n3aZahrdmpmjBoihSoAiu3Lxi06K/x8nRCd90+QZvrX8Lu87twpazW9C2SlvL8laVWqGTVyesPb0W\n//3jv/D4wgO+3/pi74W9aFa+WbbfY0bSPtdxLPoYapepbbfys4NdN2QXjTwb4WDkQSRrsuWp2Iz8\n1vc3BEQFYOKOiVh+fDleqP0CAGDmgZl45/F38Frj1wAAwzcMx5JeS2y2nx8wH683eT3d7oCH0Xut\n38OG0xtQwKEAWldqbZkvIvAq6YXnlz2PA5EH0KZym2yXfS/okzUZZ2PPZrlFf08DzwZwK+KGLWe2\noKNXR5vlhy8ehn+oP45FH7M8FZsdXby74Lllz9nMP37pOEJiQvBk9SezXWYF5woYuWkkwuLC4FPK\nJ911Onp1xLO1nsXwDcNRt0xdPFb6McuyAg4F8FWXryzTkdcicenGJRR3Kp7hvZacKF2sNIoWLIpz\n8cZw4xOXT1jVIy8x6Mku3Iu6w72IO/7167+QrMn3vcHnU8oHPqV8UMKpBN7Z9A6ee+w5RCdEY8vZ\nLZjbYy4A4IM2H6DOjDpoPKsxXAu7YmrXqahVuhbCYsMQEBWA7jW659Vby7UqrlUwpPGQdJfN6zkP\nIVdDMLbN2ByduLzdvLEhZAMirkXAtbBrjsp4teGrGLR6ECq7VMaolqPwtM/TAIwH355e8jS6enfF\nwPoDs30SAYzhrol3EuH5pSfcirjh5Xovo02VNpi5fyYG1h+Igo4Fs13mpI6TcCT6COY+PRdOjk4Z\nrvdFpy+yVJ5nCU94lkj/+YDc8vXwRcBF4/OiShUtBedCzg9kP5mR9PpKH9jORDQv90d5a+vZrThx\n+QQqOFewhMX9qCqaz2mObt7dEHEtAsmajNlP//1U4aWESzgbexYHIg5gjP8YjHx8JA5dPASXQi74\ntvu3D/KtPDJOXj6Jbou6YXz78Zi6dyq2D8r+xwAkazL2nN+DiGsRGPr7UOx8ZSe83bwx1n8sTl4+\niaXPLc1VHeMT43H99nWExoZi1oFZOHbpGIoUKIKFzy584H3T+W3UplFwKeSCuh7GQ4Vr+6/NUTki\nAlWVnNaDQU/5au+FvZiwfQIcxAGftf8swy9a2HVuF+YHzIeIYOTjI1G1ZNU8runDKfFOIprPaY74\nxHi86PsixvqNzVV5M/bNwPR90/Fk9Scx59AcHBpyyPRh/CAtClyEafumoaJzRVRxrYLPO36eo3IY\n9ERkN6qKHw//iOiEaDT0bJhuvz1l3cXrF/GR/0e4q3fxWuPX0NCzYY7KYdATEZlcboOewyuJiEyO\nQU9EZHIMeiIik2PQExGZHIOeiMjkGPRERCaXpaAXkS4iclJEgkRkdAbrfCMiwSJyWETq27eaRESU\nU5kGvYg4AJgGoDOA2gD6ikjNNOt0BeClqtUBDAHwnU1BZHf+/v75XQVT4fG0Hx7Lh0tWWvRNAQSr\napiqJgFYCiDtt0b0ADAfAFR1DwAXEfGwa03JBv+Y7IvH0354LB8uWQn68gDOpZo+nzLvfutcSGcd\nIiLKB7wZS0Rkcpl+1o2INAcwVlW7pEy/C+MbySemWuc7AFtV9aeU6ZMA2qhqVJqy+EE3REQ5kJvP\nusnKF4/sA+AtIpUBRALoA6BvmnVWA3gdwE8pJ4bYtCGf24oSEVHOZBr0qnpXRIYB2Aijq2eOqp4Q\nkSHGYp2lqmtFpJuInAaQAGDgg602ERFlVZ5+TDEREeW9PLsZm5WHrihjIhIqIgEickhE9qbMKyki\nG0XklIhsEBH7fbOxyYjIHBGJEpHAVPMyPH4i8l7KA4AnRKRT/tT64ZXB8RwjIudF5GDKT5dUy3g8\nMyAiFUTkDxE5JiJHROTNlPn2+/1U1Qf+A+OEchpAZQAFARwGUDMv9m2WHwBnAJRMM28igFEpr0cD\nmJDf9XxYfwC0AlAfQGBmxw/AYwAOwejarJLyuyv5/R4epp8MjucYACPSWbcWj+d9j2VZAPVTXhcH\ncApATXv+fuZViz4rD13R/Qlsr8B6AJiX8noegJ55WqNHiKpuB3A1zeyMjt/TAJaq6h1VDQUQDON3\nmFJkcDwB4/c0rR7g8cyQql5U1cMpr68DOAGgAuz4+5lXQZ+Vh67o/hTAJhHZJyKvpszz0JTRTap6\nEUCZfKvdo6lMBsePDwDm3LCUz7v6PlVXA49nFolIFRhXSruR8d93to8nH5h6dLRU1YYAugF4XURa\nwwj/1HhnPXd4/HJnBoBqqlofwEUAX+ZzfR4pIlIcwHIA/0lp2dvt7zuvgv4CgEqppiukzKMsUtXI\nlH8vAfgVxqVa1L3PFBKRsgCi86+Gj6SMjt8FABVTrcff1yxQ1Uua0okMYDb+7k7g8cyEiBSAEfIL\nVHVVymy7/X7mVdBbHroSEScYD12tzqN9P/JEpGjK2R4iUgxAJwBHYBzDl1NW+xeAVekWQPcIrPuQ\nMzp+qwH0EREnEakKwBvA3ryq5CPE6nimhNE9zwI4mvKaxzNzcwEcV9WvU82z2+9nVp6MzTXN4KGr\nvNi3SXgAWJnyERIFACxS1Y0ish/AzyIyCEAYgBfys5IPMxFZDMAPgLuIhMMYITIBwLK0x09Vj4vI\nzwCOA0gC8O9ULVVChsezbcp3USQDCIXxkeU8npkQkZYA+gM4IiKHYHTR/BfGqBubv++cHE8+MEVE\nZHK8GUtEZHIMeiIik2PQExGZHIOeiMjkGPRERCbHoCciMjkGPRGRyTHoiYhM7v8BhqJnQZefWX4A\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x159090b50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_accuracies)\n",
    "plt.plot(test_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-17T06:31:15.438519",
     "start_time": "2016-06-17T06:31:15.434942"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98040003"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(test_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number test errors is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-17T06:31:17.633844",
     "start_time": "2016-06-17T06:31:17.630231"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195.99974155426025"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10000*(1.0-np.max(test_accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-17T06:31:18.158336",
     "start_time": "2016-06-17T06:31:18.155316"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.000018, 51.163795, 0.9999997, 2.7130308, 0.38692814, 0.026154401]\n",
      "[48.747219, 48.928699, 0.99999994, 2.7886932, 0.27928257, 0.0024301391]\n"
     ]
    }
   ],
   "source": [
    "print norms[0]\n",
    "print norms[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-14T16:33:49.528886",
     "start_time": "2016-06-14T16:33:49.525098"
    }
   },
   "source": [
    "#### What is the best way to implement the cutoff ?\n",
    "\n",
    "by the norm of the weights at each layer ?\n",
    "\n",
    "see also:  http://keras.io/constraints/\n",
    "\n",
    "Does this just reflect the loss decreasing ?\n",
    "\n",
    "Can we simply bound the norm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-16T22:32:15.292684",
     "start_time": "2016-06-17T05:30:25.992Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(6):\n",
    "    plt.plot([nrm[i] for nrm in norms])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-16T15:28:16.845184",
     "start_time": "2016-06-16T15:28:16.842225"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 164\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
