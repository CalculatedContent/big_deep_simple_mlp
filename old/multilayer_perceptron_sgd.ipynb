{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-19T17:07:45.399603",
     "start_time": "2016-04-19T17:07:45.395689"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A Multilayer Perceptron implementation example using TensorFlow library.\n",
    "# This example is using the MNIST database of handwritten digits\n",
    "# (http://yann.lecun.com/exdb/mnist/)\n",
    "\n",
    "# Author: Aymeric Damien\n",
    "# Project: https://github.com/aymericdamien/TensorFlow-Examples/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-19T17:07:47.974706",
     "start_time": "2016-04-19T17:07:46.695245"
    },
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./train-images-idx3-ubyte.gz\n",
      "Extracting ./train-labels-idx1-ubyte.gz\n",
      "Extracting ./t10k-images-idx3-ubyte.gz\n",
      "Extracting ./t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlesmartin14/anaconda2/lib/python2.7/gzip.py:275: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n",
      "  chunk = self.extrabuf[offset: offset + size]\n",
      "input_data.py:35: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n",
      "  data = data.reshape(num_images, rows, cols, 1)\n"
     ]
    }
   ],
   "source": [
    "# Import MINST data\n",
    "import input_data\n",
    "mnist = input_data.read_data_sets(\".\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-19T17:07:49.743573",
     "start_time": "2016-04-19T17:07:47.975941"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-19T18:16:12.686741",
     "start_time": "2016-04-19T18:16:12.682657"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "#learning_rate = 0.001\n",
    "training_epochs = 5000\n",
    "batch_size = 100\n",
    "display_step = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-19T18:16:13.141885",
     "start_time": "2016-04-19T18:16:13.137953"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer num features\n",
    "n_hidden_2 = 256 # 2nd layer num features\n",
    "n_input = 784 # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "\n",
    "std_0 = 1.0/np.sqrt(n_input)\n",
    "std_h1 = 1.0/np.sqrt(n_hidden_1)\n",
    "std_h2 = 1.0/np.sqrt(n_hidden_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-19T18:16:13.294101",
     "start_time": "2016-04-19T18:16:13.290571"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-19T18:16:13.469849",
     "start_time": "2016-04-19T18:16:13.465625"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "def multilayer_perceptron(_X, _weights, _biases):\n",
    "    #Hidden layer with RELU activation\n",
    "    layer_1 = tf.nn.relu(tf.add(tf.matmul(_X, _weights['h1']), _biases['b1'])) \n",
    "    #Hidden layer with RELU activation\n",
    "    layer_2 = tf.nn.relu(tf.add(tf.matmul(layer_1, _weights['h2']), _biases['b2'])) \n",
    "    return tf.matmul(layer_2, weights['out']) + biases['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-19T18:16:13.659412",
     "start_time": "2016-04-19T18:16:13.620527"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1], stddev=std_0)),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2], stddev=std_h1)),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes], stddev=std_h2))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1], stddev=std_0)),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2], stddev=std_h1)),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes], stddev=std_h2))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-19T18:16:13.800148",
     "start_time": "2016-04-19T18:16:13.794488"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct model\n",
    "pred = multilayer_perceptron(x, weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-19T18:16:14.153028",
     "start_time": "2016-04-19T18:16:14.147237"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-19T18:16:14.400629",
     "start_time": "2016-04-19T18:16:14.339848"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global_step = tf.Variable(0, trainable=False)\n",
    "starter_learning_rate = 0.01\n",
    "learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step, 100000, 0.96, staircase=True)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-19T18:16:14.529565",
     "start_time": "2016-04-19T18:16:14.526912"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-20T02:17:20.527428",
     "start_time": "2016-04-19T18:16:14.710322"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 1.295379812\n",
      "Accuracy: 0.8569\n",
      "Epoch: 0026 cost= 0.121481457\n",
      "Accuracy: 0.9615\n",
      "Epoch: 0051 cost= 0.062198018\n",
      "Accuracy: 0.9729\n",
      "Epoch: 0076 cost= 0.036098947\n",
      "Accuracy: 0.9772\n",
      "Epoch: 0101 cost= 0.022404282\n",
      "Accuracy: 0.9792\n",
      "Epoch: 0126 cost= 0.014658992\n",
      "Accuracy: 0.9797\n",
      "Epoch: 0151 cost= 0.010097439\n",
      "Accuracy: 0.9791\n",
      "Epoch: 0176 cost= 0.007250372\n",
      "Accuracy: 0.9796\n",
      "Epoch: 0201 cost= 0.005493795\n",
      "Accuracy: 0.9798\n",
      "Epoch: 0226 cost= 0.004285184\n",
      "Accuracy: 0.9794\n",
      "Epoch: 0251 cost= 0.003452002\n",
      "Accuracy: 0.9798\n",
      "Epoch: 0276 cost= 0.002852096\n",
      "Accuracy: 0.9802\n",
      "Epoch: 0301 cost= 0.002410825\n",
      "Accuracy: 0.9799\n",
      "Epoch: 0326 cost= 0.002073553\n",
      "Accuracy: 0.9799\n",
      "Epoch: 0351 cost= 0.001808492\n",
      "Accuracy: 0.9799\n",
      "Epoch: 0376 cost= 0.001604689\n",
      "Accuracy: 0.9803\n",
      "Epoch: 0401 cost= 0.001439368\n",
      "Accuracy: 0.9801\n",
      "Epoch: 0426 cost= 0.001300073\n",
      "Accuracy: 0.9803\n",
      "Epoch: 0451 cost= 0.001182989\n",
      "Accuracy: 0.9803\n",
      "Epoch: 0476 cost= 0.001082277\n",
      "Accuracy: 0.9803\n",
      "Epoch: 0501 cost= 0.000997002\n",
      "Accuracy: 0.9805\n",
      "Epoch: 0526 cost= 0.000921424\n",
      "Accuracy: 0.9805\n",
      "Epoch: 0551 cost= 0.000856836\n",
      "Accuracy: 0.9803\n",
      "Epoch: 0576 cost= 0.000801690\n",
      "Accuracy: 0.9806\n",
      "Epoch: 0601 cost= 0.000751212\n",
      "Accuracy: 0.9804\n",
      "Epoch: 0626 cost= 0.000706963\n",
      "Accuracy: 0.9804\n",
      "Epoch: 0651 cost= 0.000667249\n",
      "Accuracy: 0.9804\n",
      "Epoch: 0676 cost= 0.000630109\n",
      "Accuracy: 0.9806\n",
      "Epoch: 0701 cost= 0.000597971\n",
      "Accuracy: 0.9806\n",
      "Epoch: 0726 cost= 0.000567792\n",
      "Accuracy: 0.9806\n",
      "Epoch: 0751 cost= 0.000541807\n",
      "Accuracy: 0.9807\n",
      "Epoch: 0776 cost= 0.000517511\n",
      "Accuracy: 0.9806\n",
      "Epoch: 0801 cost= 0.000495195\n",
      "Accuracy: 0.9806\n",
      "Epoch: 0826 cost= 0.000474393\n",
      "Accuracy: 0.9808\n",
      "Epoch: 0851 cost= 0.000455104\n",
      "Accuracy: 0.9805\n",
      "Epoch: 0876 cost= 0.000437123\n",
      "Accuracy: 0.9808\n",
      "Epoch: 0901 cost= 0.000420352\n",
      "Accuracy: 0.9808\n",
      "Epoch: 0926 cost= 0.000405406\n",
      "Accuracy: 0.9807\n",
      "Epoch: 0951 cost= 0.000391462\n",
      "Accuracy: 0.9807\n",
      "Epoch: 0976 cost= 0.000378009\n",
      "Accuracy: 0.9807\n",
      "Epoch: 1001 cost= 0.000365658\n",
      "Accuracy: 0.9807\n",
      "Epoch: 1026 cost= 0.000353886\n",
      "Accuracy: 0.9807\n",
      "Epoch: 1051 cost= 0.000342865\n",
      "Accuracy: 0.9807\n",
      "Epoch: 1076 cost= 0.000332412\n",
      "Accuracy: 0.9806\n",
      "Epoch: 1101 cost= 0.000322648\n",
      "Accuracy: 0.9807\n",
      "Epoch: 1126 cost= 0.000313626\n",
      "Accuracy: 0.9809\n",
      "Epoch: 1151 cost= 0.000305089\n",
      "Accuracy: 0.9807\n",
      "Epoch: 1176 cost= 0.000296786\n",
      "Accuracy: 0.9808\n",
      "Epoch: 1201 cost= 0.000289121\n",
      "Accuracy: 0.9807\n",
      "Epoch: 1226 cost= 0.000281581\n",
      "Accuracy: 0.9807\n",
      "Epoch: 1251 cost= 0.000274457\n",
      "Accuracy: 0.9806\n",
      "Epoch: 1276 cost= 0.000267775\n",
      "Accuracy: 0.9807\n",
      "Epoch: 1301 cost= 0.000261551\n",
      "Accuracy: 0.9807\n",
      "Epoch: 1326 cost= 0.000255527\n",
      "Accuracy: 0.9808\n",
      "Epoch: 1351 cost= 0.000249739\n",
      "Accuracy: 0.9806\n",
      "Epoch: 1376 cost= 0.000244264\n",
      "Accuracy: 0.9807\n",
      "Epoch: 1401 cost= 0.000238970\n",
      "Accuracy: 0.9808\n",
      "Epoch: 1426 cost= 0.000233884\n",
      "Accuracy: 0.9808\n",
      "Epoch: 1451 cost= 0.000228991\n",
      "Accuracy: 0.9806\n",
      "Epoch: 1476 cost= 0.000224425\n",
      "Accuracy: 0.9807\n",
      "Epoch: 1501 cost= 0.000220081\n",
      "Accuracy: 0.9807\n",
      "Epoch: 1526 cost= 0.000215796\n",
      "Accuracy: 0.9806\n",
      "Epoch: 1551 cost= 0.000211742\n",
      "Accuracy: 0.9807\n",
      "Epoch: 1576 cost= 0.000207775\n",
      "Accuracy: 0.9806\n",
      "Epoch: 1601 cost= 0.000203982\n",
      "Accuracy: 0.9808\n",
      "Epoch: 1626 cost= 0.000200259\n",
      "Accuracy: 0.9805\n",
      "Epoch: 1651 cost= 0.000196793\n",
      "Accuracy: 0.9807\n",
      "Epoch: 1676 cost= 0.000193508\n",
      "Accuracy: 0.9805\n",
      "Epoch: 1701 cost= 0.000190238\n",
      "Accuracy: 0.9805\n",
      "Epoch: 1726 cost= 0.000187119\n",
      "Accuracy: 0.9807\n",
      "Epoch: 1751 cost= 0.000184085\n",
      "Accuracy: 0.9805\n",
      "Epoch: 1776 cost= 0.000181116\n",
      "Accuracy: 0.9806\n",
      "Epoch: 1801 cost= 0.000178258\n",
      "Accuracy: 0.9805\n",
      "Epoch: 1826 cost= 0.000175495\n",
      "Accuracy: 0.9806\n",
      "Epoch: 1851 cost= 0.000172914\n",
      "Accuracy: 0.9806\n",
      "Epoch: 1876 cost= 0.000170393\n",
      "Accuracy: 0.9805\n",
      "Epoch: 1901 cost= 0.000167939\n",
      "Accuracy: 0.9805\n",
      "Epoch: 1926 cost= 0.000165521\n",
      "Accuracy: 0.9805\n",
      "Epoch: 1951 cost= 0.000163169\n",
      "Accuracy: 0.9805\n",
      "Epoch: 1976 cost= 0.000160877\n",
      "Accuracy: 0.9806\n",
      "Epoch: 2001 cost= 0.000158693\n",
      "Accuracy: 0.9805\n",
      "Epoch: 2026 cost= 0.000156587\n",
      "Accuracy: 0.9805\n",
      "Epoch: 2051 cost= 0.000154549\n",
      "Accuracy: 0.9805\n",
      "Epoch: 2076 cost= 0.000152586\n",
      "Accuracy: 0.9805\n",
      "Epoch: 2101 cost= 0.000150614\n",
      "Accuracy: 0.9806\n",
      "Epoch: 2126 cost= 0.000148744\n",
      "Accuracy: 0.9805\n",
      "Epoch: 2151 cost= 0.000146887\n",
      "Accuracy: 0.9805\n",
      "Epoch: 2176 cost= 0.000145050\n",
      "Accuracy: 0.9804\n",
      "Epoch: 2201 cost= 0.000143337\n",
      "Accuracy: 0.9805\n",
      "Epoch: 2226 cost= 0.000141674\n",
      "Accuracy: 0.9804\n",
      "Epoch: 2251 cost= 0.000140043\n",
      "Accuracy: 0.9806\n",
      "Epoch: 2276 cost= 0.000138437\n",
      "Accuracy: 0.9805\n",
      "Epoch: 2301 cost= 0.000136880\n",
      "Accuracy: 0.9804\n",
      "Epoch: 2326 cost= 0.000135344\n",
      "Accuracy: 0.9805\n",
      "Epoch: 2351 cost= 0.000133832\n",
      "Accuracy: 0.9805\n",
      "Epoch: 2376 cost= 0.000132405\n",
      "Accuracy: 0.9804\n",
      "Epoch: 2401 cost= 0.000131016\n",
      "Accuracy: 0.9804\n",
      "Epoch: 2426 cost= 0.000129658\n",
      "Accuracy: 0.9804\n",
      "Epoch: 2451 cost= 0.000128320\n",
      "Accuracy: 0.9805\n",
      "Epoch: 2476 cost= 0.000127005\n",
      "Accuracy: 0.9803\n",
      "Epoch: 2501 cost= 0.000125720\n",
      "Accuracy: 0.9804\n",
      "Epoch: 2526 cost= 0.000124465\n",
      "Accuracy: 0.9804\n",
      "Epoch: 2551 cost= 0.000123231\n",
      "Accuracy: 0.9804\n",
      "Epoch: 2576 cost= 0.000122064\n",
      "Accuracy: 0.9803\n",
      "Epoch: 2601 cost= 0.000120912\n",
      "Accuracy: 0.9804\n",
      "Epoch: 2626 cost= 0.000119783\n",
      "Accuracy: 0.9804\n",
      "Epoch: 2651 cost= 0.000118671\n",
      "Accuracy: 0.9804\n",
      "Epoch: 2676 cost= 0.000117582\n",
      "Accuracy: 0.9804\n",
      "Epoch: 2701 cost= 0.000116498\n",
      "Accuracy: 0.9804\n",
      "Epoch: 2726 cost= 0.000115437\n",
      "Accuracy: 0.9803\n",
      "Epoch: 2751 cost= 0.000114451\n",
      "Accuracy: 0.9803\n",
      "Epoch: 2776 cost= 0.000113464\n",
      "Accuracy: 0.9803\n",
      "Epoch: 2801 cost= 0.000112502\n",
      "Accuracy: 0.9804\n",
      "Epoch: 2826 cost= 0.000111546\n",
      "Accuracy: 0.9803\n",
      "Epoch: 2851 cost= 0.000110601\n",
      "Accuracy: 0.9803\n",
      "Epoch: 2876 cost= 0.000109682\n",
      "Accuracy: 0.9803\n",
      "Epoch: 2901 cost= 0.000108770\n",
      "Accuracy: 0.9803\n",
      "Epoch: 2926 cost= 0.000107905\n",
      "Accuracy: 0.9804\n",
      "Epoch: 2951 cost= 0.000107049\n",
      "Accuracy: 0.9803\n",
      "Epoch: 2976 cost= 0.000106215\n",
      "Accuracy: 0.9803\n",
      "Epoch: 3001 cost= 0.000105386\n",
      "Accuracy: 0.9804\n",
      "Epoch: 3026 cost= 0.000104576\n",
      "Accuracy: 0.9804\n",
      "Epoch: 3051 cost= 0.000103770\n",
      "Accuracy: 0.9803\n",
      "Epoch: 3076 cost= 0.000102982\n",
      "Accuracy: 0.9805\n",
      "Epoch: 3101 cost= 0.000102220\n",
      "Accuracy: 0.9805\n",
      "Epoch: 3126 cost= 0.000101482\n",
      "Accuracy: 0.9805\n",
      "Epoch: 3151 cost= 0.000100751\n",
      "Accuracy: 0.9805\n",
      "Epoch: 3176 cost= 0.000100032\n",
      "Accuracy: 0.9806\n",
      "Epoch: 3201 cost= 0.000099322\n",
      "Accuracy: 0.9805\n",
      "Epoch: 3226 cost= 0.000098618\n",
      "Accuracy: 0.9805\n",
      "Epoch: 3251 cost= 0.000097925\n",
      "Accuracy: 0.9805\n",
      "Epoch: 3276 cost= 0.000097255\n",
      "Accuracy: 0.9805\n",
      "Epoch: 3301 cost= 0.000096604\n",
      "Accuracy: 0.9806\n",
      "Epoch: 3326 cost= 0.000095962\n",
      "Accuracy: 0.9806\n",
      "Epoch: 3351 cost= 0.000095329\n",
      "Accuracy: 0.9806\n",
      "Epoch: 3376 cost= 0.000094705\n",
      "Accuracy: 0.9806\n",
      "Epoch: 3401 cost= 0.000094087\n",
      "Accuracy: 0.9807\n",
      "Epoch: 3426 cost= 0.000093480\n",
      "Accuracy: 0.9806\n",
      "Epoch: 3451 cost= 0.000092875\n",
      "Accuracy: 0.9806\n",
      "Epoch: 3476 cost= 0.000092303\n",
      "Accuracy: 0.9805\n",
      "Epoch: 3501 cost= 0.000091738\n",
      "Accuracy: 0.9806\n",
      "Epoch: 3526 cost= 0.000091173\n",
      "Accuracy: 0.9806\n",
      "Epoch: 3551 cost= 0.000090621\n",
      "Accuracy: 0.9805\n",
      "Epoch: 3576 cost= 0.000090076\n",
      "Accuracy: 0.9807\n",
      "Epoch: 3601 cost= 0.000089532\n",
      "Accuracy: 0.9806\n",
      "Epoch: 3626 cost= 0.000088999\n",
      "Accuracy: 0.9806\n",
      "Epoch: 3651 cost= 0.000088483\n",
      "Accuracy: 0.9807\n",
      "Epoch: 3676 cost= 0.000087984\n",
      "Accuracy: 0.9807\n",
      "Epoch: 3701 cost= 0.000087480\n",
      "Accuracy: 0.9807\n",
      "Epoch: 3726 cost= 0.000086991\n",
      "Accuracy: 0.9806\n",
      "Epoch: 3751 cost= 0.000086501\n",
      "Accuracy: 0.9807\n",
      "Epoch: 3776 cost= 0.000086019\n",
      "Accuracy: 0.9807\n",
      "Epoch: 3801 cost= 0.000085540\n",
      "Accuracy: 0.9806\n",
      "Epoch: 3826 cost= 0.000085074\n",
      "Accuracy: 0.9806\n",
      "Epoch: 3851 cost= 0.000084626\n",
      "Accuracy: 0.9807\n",
      "Epoch: 3876 cost= 0.000084184\n",
      "Accuracy: 0.9806\n",
      "Epoch: 3901 cost= 0.000083738\n",
      "Accuracy: 0.9807\n",
      "Epoch: 3926 cost= 0.000083300\n",
      "Accuracy: 0.9807\n",
      "Epoch: 3951 cost= 0.000082869\n",
      "Accuracy: 0.9807\n",
      "Epoch: 3976 cost= 0.000082442\n",
      "Accuracy: 0.9807\n",
      "Epoch: 4001 cost= 0.000082021\n",
      "Accuracy: 0.9807\n",
      "Epoch: 4026 cost= 0.000081617\n",
      "Accuracy: 0.9807\n",
      "Epoch: 4051 cost= 0.000081216\n",
      "Accuracy: 0.9807\n",
      "Epoch: 4076 cost= 0.000080820\n",
      "Accuracy: 0.9807\n",
      "Epoch: 4101 cost= 0.000080427\n",
      "Accuracy: 0.9807\n",
      "Epoch: 4126 cost= 0.000080037\n",
      "Accuracy: 0.9807\n",
      "Epoch: 4151 cost= 0.000079649\n",
      "Accuracy: 0.9807\n",
      "Epoch: 4176 cost= 0.000079270\n",
      "Accuracy: 0.9807\n",
      "Epoch: 4201 cost= 0.000078902\n",
      "Accuracy: 0.9807\n",
      "Epoch: 4226 cost= 0.000078539\n",
      "Accuracy: 0.9807\n",
      "Epoch: 4251 cost= 0.000078183\n",
      "Accuracy: 0.9807\n",
      "Epoch: 4276 cost= 0.000077826\n",
      "Accuracy: 0.9807\n",
      "Epoch: 4301 cost= 0.000077474\n",
      "Accuracy: 0.9807\n",
      "Epoch: 4326 cost= 0.000077125\n",
      "Accuracy: 0.9807\n",
      "Epoch: 4351 cost= 0.000076780\n",
      "Accuracy: 0.9807\n",
      "Epoch: 4376 cost= 0.000076444\n",
      "Accuracy: 0.9807\n",
      "Epoch: 4401 cost= 0.000076116\n",
      "Accuracy: 0.9807\n",
      "Epoch: 4426 cost= 0.000075791\n",
      "Accuracy: 0.9807\n",
      "Epoch: 4451 cost= 0.000075468\n",
      "Accuracy: 0.9807\n",
      "Epoch: 4476 cost= 0.000075149\n",
      "Accuracy: 0.9807\n",
      "Epoch: 4501 cost= 0.000074830\n",
      "Accuracy: 0.9807\n",
      "Epoch: 4526 cost= 0.000074516\n",
      "Accuracy: 0.9807\n",
      "Epoch: 4551 cost= 0.000074208\n",
      "Accuracy: 0.9807\n",
      "Epoch: 4576 cost= 0.000073910\n",
      "Accuracy: 0.9807\n",
      "Epoch: 4601 cost= 0.000073616\n",
      "Accuracy: 0.9807\n",
      "Epoch: 4626 cost= 0.000073322\n",
      "Accuracy: 0.9807\n",
      "Epoch: 4651 cost= 0.000073030\n",
      "Accuracy: 0.9807\n",
      "Epoch: 4676 cost= 0.000072742\n",
      "Accuracy: 0.9807\n",
      "Epoch: 4701 cost= 0.000072455\n",
      "Accuracy: 0.9807\n",
      "Epoch: 4726 cost= 0.000072169\n",
      "Accuracy: 0.9807\n",
      "Epoch: 4751 cost= 0.000071899\n",
      "Accuracy: 0.9807\n",
      "Epoch: 4776 cost= 0.000071629\n",
      "Accuracy: 0.9807\n",
      "Epoch: 4801 cost= 0.000071360\n",
      "Accuracy: 0.9807\n",
      "Epoch: 4826 cost= 0.000071096\n",
      "Accuracy: 0.9807\n",
      "Epoch: 4851 cost= 0.000070830\n",
      "Accuracy: 0.9807\n",
      "Epoch: 4876 cost= 0.000070568\n",
      "Accuracy: 0.9807\n",
      "Epoch: 4901 cost= 0.000070308\n",
      "Accuracy: 0.9807\n",
      "Epoch: 4926 cost= 0.000070058\n",
      "Accuracy: 0.9807\n",
      "Epoch: 4951 cost= 0.000069811\n",
      "Accuracy: 0.9807\n",
      "Epoch: 4976 cost= 0.000069565\n",
      "Accuracy: 0.9807\n",
      "Accuracy: 0.9807\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.0\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            # Fit training using batch data\n",
    "            sess.run(optimizer, feed_dict={x: batch_xs, y: batch_ys})\n",
    "            # Compute average loss\n",
    "            avg_cost += sess.run(cost, feed_dict={x: batch_xs, y: batch_ys})/total_batch\n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            print \"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost)\n",
    "            correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "            print \"Accuracy:\", accuracy.eval({x: mnist.test.images, y: mnist.test.labels})\n",
    "\n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print \"Accuracy:\", accuracy.eval({x: mnist.test.images, y: mnist.test.labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
