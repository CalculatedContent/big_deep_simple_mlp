{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-20T21:52:04.548207",
     "start_time": "2016-04-20T21:52:04.544771"
    }
   },
   "source": [
    "### Simple MLP 7\n",
    "\n",
    "Testing new infimnist on every epoch\n",
    "\n",
    "RMSProp solver with DropOut\n",
    "\n",
    "1000 x 500 \n",
    "\n",
    "100 epochs\n",
    "\n",
    "see:  https://github.com/nlintz/TensorFlow-Tutorials/blob/master/4_modern_net.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-24T21:10:35.883033",
     "start_time": "2016-04-24T21:10:35.879664"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A Multilayer Perceptron implementation example using TensorFlow library.\n",
    "# This example is using the MNIST database of handwritten digits\n",
    "# (http://yann.lecun.com/exdb/mnist/)=\n",
    "\n",
    "\n",
    "# Author: Aymeric Damien\n",
    "# Project: https://github.com/aymericdamien/TensorFlow-Examples/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-24T21:10:38.380047",
     "start_time": "2016-04-24T21:10:36.536227"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-24T21:10:38.404194",
     "start_time": "2016-04-24T21:10:38.381415"
    },
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from subprocess import Popen\n",
    "INFIMNIST = '/Users/charlesmartin14/packages/infimnist/infimnist -d /Users/charlesmartin14/packages/infimnist/data '\n",
    "\n",
    "class InfiMNIST(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.data_dir = \".\"\n",
    "        self._infimnist_start = 10000\n",
    "        self._infimnist_stop =  self._infimnist_start + 59999\n",
    "\n",
    "    def next_epoch(self):\n",
    "        #print \"creating infimnist pat files %d - %d\" % (self._infimnist_start, self._infimnist_stop)\n",
    "        lab_file = os.path.join(self.data_dir, 'infimnist-labels')\n",
    "        pat_file = os.path.join(self.data_dir, 'infimnist-images')\n",
    "        \n",
    "        # execute cmd \n",
    "        \n",
    "        with open(lab_file, 'wb') as out:\n",
    "            cmd = \"{} lab {} {} \".format(INFIMNIST, self._infimnist_start, self._infimnist_stop)\n",
    "            #print cmd\n",
    "            Popen(cmd, shell=True, stdout=out, cwd=self.data_dir).wait()\n",
    "            \n",
    "        with open(pat_file, 'wb') as out:\n",
    "            cmd = \"{} pat {} {} \".format(INFIMNIST, self._infimnist_start, self._infimnist_stop)\n",
    "            #print cmd\n",
    "            Popen(cmd, shell=True, stdout=out, cwd=self.data_dir).wait()\n",
    "        \n",
    "        cmd1 = \"rm infimnist-labels.gz infimnist-images.gz mnist-labels.gz mnist-images.gz\"\n",
    "        cmd2 = \"gzip -f infimnist-labels infimnist-images\"\n",
    "        cmd3 = \"ln -s infimnist-labels.gz  mnist-labels.gz\"\n",
    "        cmd4 = \"ln -s infimnist-images.gz  mnist-images.gz\"\n",
    "\n",
    "        os.system(cmd1)\n",
    "        os.system(cmd2)\n",
    "        os.system(cmd3)\n",
    "        os.system(cmd4)\n",
    "        \n",
    "        self._infimnist_start = self._infimnist_stop + 1\n",
    "        self._infimnist_stop =  self._infimnist_start + 59999\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-24T21:10:38.407295",
     "start_time": "2016-04-24T21:10:38.405408"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "infiminst = InfiMNIST()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-24T21:10:41.466760",
     "start_time": "2016-04-24T21:10:41.463918"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 100\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "total_batch = 55000/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-24T21:10:44.123176",
     "start_time": "2016-04-24T21:10:44.119551"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Network Parameters\n",
    "n_hidden_1 = 1000 # 1st layer num features\n",
    "n_hidden_2 = 500 # 2nd layer num features\n",
    "n_input = 784 # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "\n",
    "std_0 = 1.0/np.sqrt(n_input)\n",
    "std_h1 = 1.0/np.sqrt(n_hidden_1)\n",
    "std_h2 = 1.0/np.sqrt(n_hidden_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-24T21:10:45.083362",
     "start_time": "2016-04-24T21:10:45.079747"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-24T21:10:46.106657",
     "start_time": "2016-04-24T21:10:46.103320"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dropout parameters\n",
    "pv = tf.placeholder(\"float\")\n",
    "ph = tf.placeholder(\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-24T21:11:09.020335",
     "start_time": "2016-04-24T21:11:09.014339"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multilayer_perceptron(_X, _weights, _biases, _pv, _ph):\n",
    "\n",
    "    _Xd = tf.nn.dropout(_X, _pv)\n",
    "    \n",
    "    layer_1 = tf.nn.relu(tf.add(tf.matmul(_Xd, _weights['h1']), _biases['b1'])) \n",
    "    layer_1d =  tf.nn.dropout(layer_1, _ph)\n",
    "    \n",
    "    layer_2 = tf.nn.relu(tf.add(tf.matmul(layer_1d, _weights['h2']), _biases['b2'])) \n",
    "    layer_2d =  tf.nn.dropout(layer_2, _ph)\n",
    "\n",
    "    \n",
    "    return tf.matmul(layer_2d, weights['out']) + biases['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-24T21:11:10.205364",
     "start_time": "2016-04-24T21:11:10.167576"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1], stddev=std_0)),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2], stddev=std_h1)),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes], stddev=std_h2))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1], stddev=std_h1)),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2], stddev=std_h2)),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes], stddev=0.3))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-24T21:11:14.347114",
     "start_time": "2016-04-24T21:11:14.326953"
    },
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Construct model\n",
    "pred = multilayer_perceptron(x, weights, biases, pv, ph )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-24T21:11:28.160406",
     "start_time": "2016-04-24T21:11:28.063239"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "# Softmax loss\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y)) \n",
    "\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(cost) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-24T21:11:30.384798",
     "start_time": "2016-04-24T21:11:30.382055"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-24T21:24:48.673050",
     "start_time": "2016-04-24T21:11:31.158010"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 0.521421121\n",
      "Accuracy: 0.9432\n",
      "Epoch: 0002 cost= 0.106560695\n",
      "Accuracy: 0.9652\n",
      "Epoch: 0003 cost= 0.063977638\n",
      "Accuracy: 0.9726\n",
      "Epoch: 0004 cost= 0.053188097\n",
      "Accuracy: 0.9736\n",
      "Epoch: 0005 cost= 0.048588691\n",
      "Accuracy: 0.9764\n",
      "Epoch: 0006 cost= 0.045269082\n",
      "Accuracy: 0.9757\n",
      "Epoch: 0007 cost= 0.047426740\n",
      "Accuracy: 0.9785\n",
      "Epoch: 0008 cost= 0.046999576\n",
      "Accuracy: 0.9787\n",
      "Epoch: 0009 cost= 0.048327359\n",
      "Accuracy: 0.9801\n",
      "Epoch: 0010 cost= 0.048431076\n",
      "Accuracy: 0.978\n",
      "Epoch: 0011 cost= 0.047490994\n",
      "Accuracy: 0.9786\n",
      "Epoch: 0012 cost= 0.051549318\n",
      "Accuracy: 0.9784\n",
      "Epoch: 0013 cost= 0.054112552\n",
      "Accuracy: 0.9815\n",
      "Epoch: 0014 cost= 0.054352083\n",
      "Accuracy: 0.9804\n",
      "Epoch: 0015 cost= 0.055207679\n",
      "Accuracy: 0.9799\n",
      "Epoch: 0016 cost= 0.054349173\n",
      "Accuracy: 0.9799\n",
      "Epoch: 0017 cost= 0.053624326\n",
      "Accuracy: 0.9794\n",
      "Epoch: 0018 cost= 0.053909233\n",
      "Accuracy: 0.9804\n",
      "Epoch: 0019 cost= 0.054537883\n",
      "Accuracy: 0.9799\n",
      "Epoch: 0020 cost= 0.059250602\n",
      "Accuracy: 0.982\n",
      "Epoch: 0021 cost= 0.053543948\n",
      "Accuracy: 0.979\n",
      "Epoch: 0022 cost= 0.054519092\n",
      "Accuracy: 0.9781\n",
      "Epoch: 0023 cost= 0.054532743\n",
      "Accuracy: 0.9821\n",
      "Epoch: 0024 cost= 0.054191260\n",
      "Accuracy: 0.98\n",
      "Epoch: 0025 cost= 0.057088642\n",
      "Accuracy: 0.9815\n",
      "Epoch: 0026 cost= 0.055815375\n",
      "Accuracy: 0.9806\n",
      "Epoch: 0027 cost= 0.057814008\n",
      "Accuracy: 0.9789\n",
      "Epoch: 0028 cost= 0.058867822\n",
      "Accuracy: 0.9829\n",
      "Epoch: 0029 cost= 0.058054866\n",
      "Accuracy: 0.9799\n",
      "Epoch: 0030 cost= 0.057190782\n",
      "Accuracy: 0.9807\n",
      "Epoch: 0031 cost= 0.054585525\n",
      "Accuracy: 0.9776\n",
      "Epoch: 0032 cost= 0.057867715\n",
      "Accuracy: 0.9807\n",
      "Epoch: 0033 cost= 0.061110734\n",
      "Accuracy: 0.9809\n",
      "Epoch: 0034 cost= 0.057887841\n",
      "Accuracy: 0.9808\n",
      "Epoch: 0035 cost= 0.059073127\n",
      "Accuracy: 0.9797\n",
      "Epoch: 0036 cost= 0.057097615\n",
      "Accuracy: 0.978\n",
      "Epoch: 0037 cost= 0.059125041\n",
      "Accuracy: 0.9809\n",
      "Epoch: 0038 cost= 0.059646691\n",
      "Accuracy: 0.9782\n",
      "Epoch: 0039 cost= 0.059015759\n",
      "Accuracy: 0.9782\n",
      "Succesfully downloaded mnist-labels.gz 304 bytes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlesmartin14/anaconda2/lib/python2.7/gzip.py:275: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n",
      "  chunk = self.extrabuf[offset: offset + size]\n",
      "input_data.py:35: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n",
      "  data = data.reshape(num_images, rows, cols, 1)\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "Not a gzipped file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-937866193624>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0minfiminst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mmnist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_data_sets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mavg_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# Loop over all batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/charlesmartin14/work/tf/big_deep_simple_mlp/input_data.pyc\u001b[0m in \u001b[0;36mread_data_sets\u001b[0;34m(train_dir, fake_data, one_hot)\u001b[0m\n\u001b[1;32m    130\u001b[0m   \u001b[0mtrain_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m   \u001b[0mlocal_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_LABELS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m   \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m   \u001b[0mlocal_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEST_IMAGES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m   \u001b[0mtest_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/charlesmartin14/work/tf/big_deep_simple_mlp/input_data.pyc\u001b[0m in \u001b[0;36mextract_labels\u001b[0;34m(filename, one_hot)\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0;31m#print('Extracting', filename)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbytestream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mmagic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytestream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmagic\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2049\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m       raise ValueError(\n",
      "\u001b[0;32m/Users/charlesmartin14/work/tf/big_deep_simple_mlp/input_data.pyc\u001b[0m in \u001b[0;36m_read32\u001b[0;34m(bytestream)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_read32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytestream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewbyteorder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'>'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytestream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0;34m\"\"\"Extract the images into a 4D uint8 numpy array [index, y, x, depth].\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/charlesmartin14/anaconda2/lib/python2.7/gzip.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextrasize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreadsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m                     \u001b[0mreadsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_read_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadsize\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/charlesmartin14/anaconda2/lib/python2.7/gzip.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_gzip_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompressobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mzlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMAX_WBITS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_member\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/charlesmartin14/anaconda2/lib/python2.7/gzip.pyc\u001b[0m in \u001b[0;36m_read_gzip_header\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mmagic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmagic\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'\\037\\213'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Not a gzipped file'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: Not a gzipped file"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "import input_data\n",
    "\n",
    "accs = []\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        infiminst.next_epoch()\n",
    "        mnist = input_data.read_data_sets(\".\", one_hot=True)\n",
    "        avg_cost = 0.0\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            # Fit training using batch data\n",
    "            sess.run(optimizer, feed_dict={x: batch_xs, y: batch_ys, pv: 0.8, ph: 0.5})\n",
    "            # Compute average loss\n",
    "            avg_cost += sess.run(cost, feed_dict={x: batch_xs, y: batch_ys, pv: 1.0, ph: 1.0})/total_batch\n",
    "            \n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            print \"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost)\n",
    "            correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "            a = accuracy.eval(feed_dict={x: mnist.test.images, y: mnist.test.labels, pv:1.0, ph:1.0})\n",
    "            accs.append(a)\n",
    "            print \"Accuracy:\", a\n",
    "\n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print \"Accuracy:\", accuracy.eval({x: mnist.test.images, y: mnist.test.labels, pv:1.0, ph:1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-24T21:24:48.674392",
     "start_time": "2016-04-25T04:11:34.355Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-24T21:24:48.674665",
     "start_time": "2016-04-25T04:11:36.586Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(accs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
